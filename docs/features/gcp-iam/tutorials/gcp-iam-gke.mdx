---
sidebar_position: 2
title: Automate GCP IAM for GKE
image: /img/quick-tutorials/gcp-iam-gke/social.png
---


Otterize automates GCP IAM roles and policies for your GCP GKE workloads, all in Kubernetes.

In this tutorial, we will:

- Optionally, spin up a GKE cluster.
- Deploy a server pod that uploads files to Google Cloud Storage, and a client pod that submits files to the server app.
- Label the server pod, telling the credentials operator to link its Kubernetes ServiceAccount with a GCP service account created for it, such that GCP workload identity federation can recognize the pod.
- Create a `ClientIntents` resource allowing the server pod to upload to GCS, that tells the intents operator to update the previously-created GCP service account with the relevant permissions.
- See that the files have been uploaded successfully.

## Prerequisites
Already have Otterize deployed with the IAM integration configured on your cluster? [Skip to the tutorial.](#tutorial)

### 1. Create a GCP GKE cluster
Before you start, you'll need an GCP GKE cluster. The cluster should have
[Workload identity federation](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) and
[Config Connector](https://cloud.google.com/config-connector/docs/how-to/install-upgrade-uninstall) installed.

<details>
<summary>How to set up a GKE cluster using gcloud CLI</summary>

  Run the following commands to configure your project and create your cluster. [Don't have gcloud? Install it now.](https://cloud.google.com/sdk/docs/install)

  1. Create a project and Set the default gcloud configurations
  ```shell
  gcloud projects create [PROJECT_NAME]
  gcloud config set project [PROJECT_NAME]
  gcloud config set compute/region [us-central1]
  ```

  2. Enable the relevant APIS
  ```shell
  gcloud services enable container.googleapis.com iamcredentials.googleapis.com cloudresourcemanager.googleapis.com
  ```
  Ensure that you have at least the following [IAM roles](https://cloud.google.com/iam/docs/understanding-roles#kubernetes-engine-roles):
  [roles/container.admin, roles/iam.serviceAccountAdmin]

  3. Create a new GKE cluster with workload identity and config connector enabled
  ```shell
  gcloud container clusters create otterize-iam-gke-tutorial \
  --release-channel regular \
  --addons ConfigConnector \
  --workload-pool=[PROJECT_NAME].svc.id.goog \
  --logging=SYSTEM \
  --monitoring=SYSTEM
  ```

</details>

Don't forget to configure your kubeconfig for your cluster. If using the example cluster above, use this command:
```bash
gcloud container clusters get-credentials otterize-iam-gke-tutorial
```

### 2. Deploy Otterize for GCP IAM
To deploy Otterize, head over to [Otterize Cloud](https://app.otterize.com) and:

1. Create a Kubernetes cluster on the [Integrations page](https://app.otterize.com/integrations), and follow the instructions. *Make sure to enable enforcement mode for this tutorial.* If you already have a Kubernetes cluster connected, skip this step.

2. Create an GCP IAM integration on the [Integrations page](https://app.otterize.com/integrations).

If you are using the cluster from the previous step, the cluster name is `otterize-iam-gke-tutorial` and the region is `us-central1`.

Once the GCP integration is configured, you'll be presented with instructions for configuring your Otterize integration with GCP IAM support.
  - **If you dont have a GCP service account for config connector**, make sure to toggle "I don't have Config Connector on my cluster". This will
    tell terraform to create a GCP service account for config connector and give it the necessary permissions to manage GCP IAM.
  - **If you have a GCP service account for config connector**, keep the "I have Config Connector deployed with a GCP service account" toggle and provide the service account name.
    This will tell terraform to use the existing service account and give it the necessary permissions to manage GCP IAM.


After Terraform has configured your cluster, click Next and you'll be presented with the configuration for deploying Otterize.
Since you now have the GCP integration enabled, you need to redeploy Otterize with GCP integration enabled flag, providing
it the client ID for the managed identity created during the terraform installation.

<details>
<summary>See how to manually configure Config Connector on your cluster for Otterize</summary>


You may also manually configure your clusters config connector to be used with Otterize.
1. Configure the GCP service account for Config Connector
    - Create a service account for Config Connector
      ```shell
        gcloud iam service-accounts create [CONFIG_CONNECTOR_SA_NAME]
      ```
    - Add the following permissions to the service account
      ```
        roles/iam.roleAdmin
        roles/iam.securityAdmin
        roles/iam.serviceAccountAdmin
        roles/iam.workloadIdentityUser
      ```
      You can use the following command to add permissions to the service account
      ```shell
        gcloud projects add-iam-policy-binding [PROJECT_NAME] \
        --member="serviceAccount:[CONFIG_CONNECTOR_SA_NAME]@[PROJECT_NAME].iam.gserviceaccount.com" \
        --role="roles/iam.roleAdmin"
      ```
    - Bind the service account to workload identity
      ```shell
        gcloud iam service-accounts add-iam-policy-binding \
        [CONFIG_CONNECTOR_SA_NAME]@[PROJECT_NAME].iam.gserviceaccount.com \
        --member="serviceAccount:[PROJECT_NAME].svc.id.goog[cnrm-system/cnrm-controller-manager]" \
        --role="roles/iam.workloadIdentityUser"
      ```
2. Apply the following YAML to your kubernetes cluster to finish the config connector configuration.
    ```yaml
    apiVersion: core.cnrm.cloud.google.com/v1beta1
    kind: ConfigConnector
    metadata:
      name: configconnector.core.cnrm.cloud.google.com
    spec:
      mode: cluster
      googleServiceAccount: "[CONFIG_CONNECTOR_SA_NAME]@[PROJECT_NAME].iam.gserviceaccount.com"
    ```

</details>

## Tutorial

### Create a GCS bucket for the server to use

First, we need to pick a  bucket name. Because GCS buckets are globally unique,
we will save the bucket name in an environment variable for use later.

```bash
export BUCKET_NAME=otterize-tutorial-bucket-`date +%s`
echo $BUCKET_NAME
```

```bash
gcloud config set project [PROJECT_NAME]
gsutil mb -c standard -l us-central1 gs://$BUCKET_NAME
```

### Deploy the sample server and client

```shell
kubectl create namespace otterize-tutorial-gcp-iam
kubectl apply -n otterize-tutorial-gcp-iam -f ${ABSOLUTE_URL}/code-examples/gcp-iam-gke/client-and-server.yaml
kubectl patch deployment -n otterize-tutorial-gcp-iam server --type='json' -p="[{\"op\": \"replace\", \"path\": \"/spec/template/spec/containers/0/env\", \"value\": [{\"name\": \"BUCKET_NAME\", \"value\": \"$BUCKET_NAME\"}]}]"
```

<details>
<summary>Expand to see the deployment YAML</summary>

```yaml
{@include: ../../../../static/code-examples/gcp-iam-gke/client-and-server.yaml}
```

</details>

### View logs for the server - access denied
The server logs will show that it fails to upload files to the GCS bucket.

```bash
kubectl logs -f -n otterize-tutorial-gcp-iam deploy/server
```

```bash
Error 403: <service_account> does not have storage.objects.create access to the Google Cloud Storage object.
# highlight-next-line
Permission 'storage.objects.create' denied on resource (or it may not exist).
```

### Label the server pod to create a GCP service account
Label the server `Pod` so that the Otterize credentials operator creates a GCP service account and binds to the pods Kubernetes ServiceAccount.
```yaml
metadata:
  labels:
    credentials-operator.otterize.com/create-gcp-sa: "true"
```

To do this, we won't be labeling the `Pod` directly, but instead patching the `template` attribute of the `Deployment` we created earlier so that it updates the `Pod`.

```bash
kubectl patch deployment -n otterize-tutorial-gcp-iam server -p '{"spec": {"template":{"metadata":{"labels":{"credentials-operator.otterize.com/create-gcp-sa":"true"}}}} }'
```

#### A GCP service account was created and bound to the server's Kubernetes ServiceAccount
Let's inspect the created service account:
```bash
gcloud iam service-accounts list --filter="otr-"
```

#### The Kubernetes ServiceAccount was annotated with the role ARN
The credentials operator automatically annotated the Kubernetes ServiceAccount for the server pod with the newly created GCP service account.

Let's look at the service account:
```bash
kubectl get serviceaccount -n otterize-tutorial-gcp-iam server -o yaml
```

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    # highlight-next-line
    iam.gke.io/gcp-service-account:
    # highlight-next-line
      otr-demo-cluster-otteri-3f630f@otterize-gcp-demo.iam.gserviceaccount.com
  name: server
```


### Apply intents to create the necessary IAM policy

By annotating the pod, we've created a GCP service account. We now need to specify what we need to access, and the intents operator will bind permissions accordingly.

We will specify the following ClientIntents, granting admin permission to the GCS bucket, and it's nested resources.
```yaml
{@include: ../../../../static/code-examples/gcp-iam-gke/clientintents.yaml}
```

To apply these intents, run the following command:
```bash
kubectl apply -n otterize-tutorial-gcp-iam -f ${ABSOLUTE_URL}/code-examples/gcp-iam-gke/clientintents.yaml
```

### The server can now upload files to GCS!

Let's look at the server logs again to see that no more errors are being reported:
```bash
kubectl logs -f -n otterize-tutorial-gcp-iam deploy/server
```

```json
{
  # highlight-next-line
  "status":200,
  "host":"server",
  "method":"POST",
  "uri":"/upload"
}
```

Let's list the contents of the S3 bucket:
```bash
gsutil ls gs://$BUCKET_NAME
```

```bash
gs://otterize-tutorial-bucket-1710338230/testfile.0.txt
gs://otterize-tutorial-bucket-1710338230/testfile.1.txt
gs://otterize-tutorial-bucket-1710338230/testfile.2.txt
gs://otterize-tutorial-bucket-1710338230/testfile.3.txt
```

### What's next?

Try out some of the other quick tutorials to learn about how to use ClientIntents to manage network policies, Istio policies, PostgreSQL access, and more. You can use a single ClientIntents resource to specify all the access required for a pod.

## Teardown

To remove the deployed examples run:

```bash
kubectl delete namespace otterize-tutorial-gcp-iam
```

To delete the cluster, if you created the one in this tutorial:
```bash
gcloud container clusters delete otterize-iam-gke-tutorial
```

To empty and delete the GCS bucket created for this tutorial:
```bash
gsutil -m rm -r gs://$BUCKET_NAME
```
