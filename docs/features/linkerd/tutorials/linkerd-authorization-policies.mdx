---
sidebar_position: 3
title: Linkerd AuthorizationPolicy automation
image: /img/quick-tutorials/k8s-linkerd-authorization-policies/social.png
---

import CodeBlock from "@theme/CodeBlock";
import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

Otterize automates mTLS-based, HTTP-level pod-to-pod access control with Linkerd authorization (authZ) policies, within your Kubernetes cluster.

Implementing this kind of access control with Linkerd can be challenging.
For example, each target server needs a matching `Server` resource, `MeshTLSAuthentication` resources need to be created & matched with identities
in order to use mTLS based authorization policies, etc. Using Otterize `ClientIntents`, this is all managed for you.

To help you avoid manually managing complicated authorization policies per server, Otterize implements **intent-based access control** (IBAC).
You just declare what calls the client pods intend to make,
and everything is automatically wired together so only intended calls are allowed.

In this tutorial, we will:

- Deploy a Linkerd demo application with two client pods and one server pod.
- Declare that the first client intends to call the server with a specific HTTP path and method.
- See that a Linkerd authorization policy was autogenerated to allow just that, and to block the (undeclared) calls from the other client.

## Prerequisites

### 1. Install Linkerd
Install Linkerd by following the [Installing Linkerd](https://linkerd.io/2-edge/tasks/install/) tutorial.

### 2. Deploy Otterize
If you do not have a cluster, we will need to prepare one with [network policy support](/overview/installation#create-a-cluster-with-support-for-network-policies)

To deploy Otterize, head over to [Otterize Cloud](https://app.otterize.com) and associate a Kubernetes cluster on the [Integrations page](https://app.otterize.com/integrations), and follow the instructions. If you already have a Kubernetes cluster connected, skip this step.

## Tutorial

### Deploy the two clients and the server

Deploy a simple example consisting of `client` and `other-client` calling `nginx` over HTTP:

```shell
curl ${ABSOLUTE_URL}/code-examples/linkerd-authorization-policies/all.yaml | linkerd inject - | kubectl apply -f -
```

Notice we use `linkerd inject` from Linkerd's CLI beforce we apply our resources to Kubernetes, to include them as part of the mesh.

### Apply intents

We will now declare that the **client** intends to call the **server** at a particular HTTP path using a specific HTTP method.

When the intents YAML is applied, creating a custom resource of type `ClientIntents`,
Otterize will add a Linkerd authorization policy to allow the intended call
(**client** &rarr; **server** with the declared path and method) and block all unintended calls (e.g., **client-other** &rarr; **server**).

:::tip

You can click on the services or the lines connecting them to see which ClientIntents you need to apply to make the connection go green!

:::

1. Here is the `intents.yaml` declaration of the client, which we will apply below:

```yaml
{@include: ../../../../static/code-examples/linkerd-authorization-policies/intents.yaml}
```

To apply it, use:
```shell
kubectl apply -n otterize-tutorial-linkerd -f ${ABSOLUTE_URL}/code-examples/linkerd-authorization-policies/intents.yaml
```
### See it in action

<details>
    <summary>Optional: check deployment status</summary>
    Check that the client and server pods were deployed

    ```bash
    kubectl get pods -n otterize-tutorial-linkerd
    ```

    You should see

    ```
    NAME                           READY   STATUS    RESTARTS   AGE
    client-68b775f766-749r4         2/2     Running   0          32s
    nginx-c646898-2lq7l             2/2     Running   0          32s
    other-client-74cc54f7b5-9rctd   2/2     Running   0          32s
    ```

</details>

monitor both client attempts to call the server with additional terminal windows,
so we can see the effects of our changes in real time.

2. **Open a new terminal window [client]** and tail the client log:

```bash
kubectl logs -f --tail 1 -n otterize-tutorial-linkerd deploy/client
```

<details>
    <summary>Expected output</summary>

    At this point the client should be able to communicate with the server:

    ```
    Calling server...
    HTTP/1.1 200 OK
    ...
    hello from /client-path
    ```

</details>

3. **Open another terminal window [client-other]** and tail the other-client log:

```bash
kubectl logs -f --tail 1 -n otterize-tutorial-linkerd deploy/other-client
```

<details>
    <summary>Expected output</summary>

    At this point the client should be able to communicate with the server:

    ```
    Calling server...
    HTTP/1.1 200 OK
    ...
    hello from /other-client-path
    ```

</details>

Keep an eye on the logs being tailed in the **[other-client]** terminal window,
and apply this `intents.yaml` file in your **main terminal window** using:

```shell
kubectl apply -f ${ABSOLUTE_URL}/code-examples/linkerd-authorization-policies/intents.yaml
```

:::tip
Client intents are the cornerstone of [intent-based access control (IBAC)](/overview/intent-based-access-control).
::: 2. You should quickly see in the **[other-client]** terminal that it times out when calling the server,
as expected since it didn't declare its intents:

```bash
Calling server...
HTTP/1.1 200 OK
...
hello from /other-client-path  # <- before applying the intents file
# highlight-start
Calling server...              # <- after applying the intents file
curl timed out
Terminated
# highlight-end
```

3. And in the **[client]** terminal you should see that calls go through, as expected since they were declared:

```bash
Calling server...
HTTP/1.1 200 OK
...
hello from /client-path
```

4. You should also see that a new Istio authorization policy was created:

```bash
kubectl get authorizationpolicies.policy.linkerd.io -n otterize-tutorial-linkerd
```

This should return:

```
NAME                                                                AGE
authpolicy-to-nginx-port-80-from-client-client-<client-hash>        2m49s
```

If you've attached Otterize OSS to Otterize Cloud, go back to see the [access graph in your browser](https://app.otterize.com):

![Access graph](/img/quick-tutorials/k8s-istio-authorization-policies/protected.png)

And upon clicking the green arrow:
![Access graph](/img/quick-tutorials/k8s-istio-authorization-policies/protected-edge.png)

It's now clear what happened:

1. The server is now protected, and is also blocking some of its clients.
2. Calls from **[client]** &rarr; **[nginx]** are declared and therefore allowed (green arrow).
3. Calls from **[client-other]** &rarr; **[nginx]** are not declared and therefore blocked (red arrow). Click on the arrow to see what to do about it.

:::tip Done!
Otterize did its job of both protecting the server _and_ allowing intended access.
:::

### What did we accomplish?

- Controlling access through Linkerd authorization policies no longer means touching authorization policies at all.

- The server is now protected, and can be accessed only by clients which declared their intents, authenticated via mTLS connection with specific certificates.

- Clients simply declare what they need to access with their intents files.

- The next `kubectl apply` ensures that authorization policies automatically reflect the most recent intended pod-to-pod access.

<details>
    <summary>Expand to see what happened behind the scenes</summary>

    Otterize generated a specific Linkerd authorization policy on the ingress of the pod of the server, allowing the server to
    be accessed by the pod of the client, based on that client's declared intent. Otterize uses labels to define the authorization policy and associate it
    with a server in a namespace, and uses service accounts to identify clients, as Istio requires. This happens as follows:

    1. The server's pod is given a label `intents.otterize.com/server` whose value uniquely represents that server.
    The Istio authorization policy stipulates that it applies to the ingress of server pods with this label.
    2. The client's service account is looked up through its pod, and used in the policy.
    The authorization policy stipulates that only services with this service account can access the server.
    In the event that the service account is shared by multiple services, an Event is placed on the `ClientIntent` to warn about this, which is also picked up as a warning in Otterize Cloud, if connected.

    Otterize saved us from doing all this work: by simply declaring the client's intents in `intents.yaml`,
    all the appropriate configuration was managed automatically behind the scenes.

</details>

:::tip Bonus tutorial
Try to create an intents file yourself for **client-other**, and apply it to allow this other client to call the server.
:::

## Teardown

To remove Linkerd and the deployed examples run:

```bash
linkerd uninstall | kubectl delete -f -
kubectl delete namespace otterize-tutorial-linkerd
```
