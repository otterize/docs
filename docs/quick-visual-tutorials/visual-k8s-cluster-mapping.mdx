---
sidebar_position: 1
title: "Visual tutorial: Kubernetes cluster mapping"
sidebar_label: "Kubernetes cluster mapping"
---

import CodeBlock from "@theme/CodeBlock";
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Otterize Cloud extends the capabilities of Otterize OSS.
We'll start by exploring a visual map of a Kubernetes cluster, based on the map information accumulated by the Otterize OSS network mapper running in the cluster.

In this tutorial, we will:

- Deploy a demo set of services based on the [Google microservices demo](https://github.com/GoogleCloudPlatform/microservices-demo),
a demo e-commerce application, into a Kubernetes cluster.
- Create an Otterize Cloud account, and install Otterize OSS (including its network mapper) in the cluster, connected to your Cloud account.
- Visualize the cluster network map in Otterize Cloud.

## Prerequisites
<details>
<summary>Prepare a cluster</summary>

Before you start, you'll need a Kubernetes cluster.

While you won't need [network policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/) in this tutorial,
you'll use them in the next tutorial, so you may just want to install them now. Otherwise, feel free to skip that aspect.

{@include: ../_common/cluster-setup.md}
</details>

## Deploy the demo set of services

To deploy these into your cluster:
```bash
kubectl create namespace otterize-ecom-demo
kubectl apply -n otterize-ecom-demo -f https://docs.otterize.com/code-examples/shadow-mode/ecom-demo.yaml
```

<details>
<summary>Optional: check that the demo was deployed...</summary>
<div>


To see all the pods in the demo:
```bash
kubectl get pods -n otterize-ecom-demo
```
The pods should all be ready and running:
```bash
NAME                                     READY   STATUS    RESTARTS      AGE
adservice-65494cbb9d-5lrv6               1/1     Running   0             115s
cartservice-6d84fc45bb-hdtwn             1/1     Running   0             115s
checkoutservice-5599486df-dvj9n          1/1     Running   3 (79s ago)   115s
currencyservice-6d64686d74-lxb7x         1/1     Running   0             115s
emailservice-7c6cbfbbd7-xjxlt            1/1     Running   0             115s
frontend-f9448d7d4-6dmnr                 1/1     Running   0             115s
kafka-0                                  1/1     Running   2 (83s ago)   115s
loadgenerator-7f6987f59-bchgm            1/1     Running   0             114s
orderservice-7ffdbf6df-wzzfd             1/1     Running   0             115s
otterize-ecom-demo-zookeeper-0           1/1     Running   0             115s
paymentservice-86855d78db-zjjfn          1/1     Running   0             115s
productcatalogservice-5944c7f666-2rjc6   1/1     Running   0             115s
recommendationservice-6c8d848498-zm2rm   1/1     Running   0             114s
redis-cart-6b79c5b497-xpms2              1/1     Running   0             115s
shippingservice-85694cb9bd-v54xp         1/1     Running   0             114s
```

</div>
</details>

<details>
<summary>Optional: Browse the demo</summary>
<Tabs groupId="frontend-addr">
<TabItem value="k8s" label="K8s">

To get the externally-accessible URL where your demo front end is available, run:
```bash
kubectl get service -n otterize-ecom-demo frontend-external | awk '{print $4}'
```
The result should be similar to (if running on AWS EKS):
```
a11843075fd254f8099a986467098647-1889474685.us-east-1.elb.amazonaws.com
```
Go ahead and browse to the URL above to "shop" and get a feel for the demo's behavior.
(The URL might take some time to populate across DNS servers. Note that we are accessing an HTTP and not an HTTPS website.)
</TabItem>
<TabItem value="minikube" label="Minikube">

To get the externally-accessible URL where your demo front end is available, run:
```
kubectl port-forward -n otterize-ecom-demo service/frontend-external 8080:80 &
```
The demo is now accessible at:
```
http://localhost:8080
```
Go ahead and browse to the URL above to "shop" and get a feel for the demo's behavior.
</TabItem>
</Tabs>
</details>

## Create an Otterize Cloud account

If you don't already have an account, browse to [https://app.otterize.com](https://app.otterize.com) to set one up.

If someone in your team has already created an org in Otterize Cloud, and invited you (using your email address), you may see an invitation to accept.

Otherwise, you'll create a new org, which you can later rename, and invite your team mates to join you there.

## Install Otterize OSS

If no Kubernetes clusters are connected to your account, click the "connect your cluster" button to:
1. Create a Cloud cluster object, specifying its name and the name of an environment to which all namespaces in that cluster will belong, by default.
2. Connect it with your actual Kubernetes cluster, by clicking on the "Connection guide &rarr;" link and running the Helm commands shown there.

<details>
<summary>More details, if you're curious</summary>

Connecting your cluster simply entails installing Otterize OSS via Helm, using credentials from your account so Otterize OSS can report information needed to visualize the cluster.

The credentials will already be inlined into the Helm command shown in the Cloud UI, so you just need to copy that line and run it from your shell.
If you don't give it the Cloud credentials, Otterize OSS will run fully standalone in your cluster &mdash; you just won't have the visualization in Otterize Cloud.

The Helm command shown in the Cloud UI also includes flags to turn off enforcement: Otterize OSS will be running in "shadow mode," meaning that it will not create network policies to restrict pod-to-pod traffic, or create Kafka ACLs to control access to Kafka topics. Instead, it will report to Otterize Cloud what **would** happen if enforcement were to be enabled, guiding you to implement IBAC without blocking intended access.
</details>

## Visualizing the cluster via the access graph

In the Otterize Cloud UI, your [cluster](https://app.otterize.com/clusters) should now show all 3 Otterize OSS operators &mdash; the intents operator, network mapper, and credentials operator &mdash; as connected, with a green status.

And when you go back to the [access graph](https://app.otterize.com/access-graph) (and select your cluster from the dropdown, if needed), you should see the following map for the demo running in your cluster:

<img src="/img/quick-tutorials/shadow-mode/phase-0.png" alt="Discovered intents" width="600"/>

:::danger
Update the image with an up to date one, and make sure there are arrows showing the direction of access.
:::

Each service is shown as a node in the access graph, while the thick lines (edges) connecting the services show access between them, as detected by the network mapper.

### The network map of the cluster

If only the network mapper were connected to the Cloud, the services would be shown without the lock icons, and the thick connecting lines would be shown in blue, because we would have no more information about what access is or would be blocked once enforcement were turned on. The network mapper gives insights on which services are trying to, or actually are, calling other services, which already provides useful insights. We call these "discovered intents": the intent of the client service to call the server service is discovered by the attempt to call the server service, not by an explicit declaration.

### Understanding access and building confidence

Now, because the intents operator is also connected, we get additional information, namely on access controls -- in this case, only pod-to-pod access, because we have not put in any Kafka-specific access configurations.

The services all show "unlocked" icons because access to them is not restricted (via network policies): that makes sense, because the intents operator is in shadow mode, and because we didn't (so far) tell Otterize Cloud that there is a global default-deny network policy in place. Note that the locks are also green, meaning that the services would not block any of their clients even if you were to turn enforcement on. And similarly, all the thick connecting lines between the services are green: none of them would be blocked if enforcement were turned on. Why?

 The access graph tells you the answer. Note the red warning icons on the services. Click on a service and you'll see that it won't be protected at all even if you did turn on enforcement! Why? Without a global default-deny network policy, a service is protected once it has at least one network policy applied to it. That will happen as soon as at least one of its clients declares its intent to call the service. So the access graph explains that you need to declare and apply the intents from clients that should be calling this service. Once you do that, and turn on enforcement, those clients will be guaranteed access because Otterize will create network policies for them, and in so doing, any undeclared calls will be blocked: the service will be protected.

 And how do we know which intents are missing? Note that each thick connecting line has a hollow center: a missing intent that was not applied. You can click on that line and see that information in detail. Declaring and applying the intent corresponding to that line will ensure that client has access to that server, and it will also protect that server. If a second client of that server declares and applies its intent, the first client will be blocked if it didn't also declare its intent.

In short, the access graph will provide insights about the current access to services, and will guide you to roll out IBAC responsibly and confidently, showing which intents need to be applied to both ensure access and protect servers.

To see this in action, proceed to the next tutorial, below.

## What's next
- Gradually [roll out IBAC](/quick-visual-tutorials/visual-ibac-network-policies) in this demo, controlling pod-to-pod access via network policies.
- Learn how to [manage secure access for Kafka](/quick-visual-tutorials/visual-ibac-kafka-k8s) in this same demo.

## Teardown

To remove the deployed reference lab run:

```bash
kubectl delete -n otterize-ecom-demo -f https://docs.otterize.com/code-examples/shadow-mode/all.yaml
kubectl delete -n otterize-ecom-demo -f https://docs.otterize.com/code-examples/shadow-mode/ecom-demo.yaml
kubectl delete namespace otterize-ecom-demo
```