---
sidebar_position: 1
title: Automate network policies
---
import CodeBlock from "@theme/CodeBlock";
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Otterize automates pod-to-pod access control with network policies, within your cluster.

Instead of managing pod identities, labeling clients, servers and namespaces,
and manually authoring individual network policies, Otterize implements **intent-based access control** (IBAC).
You just declare what calls the client pods intend to make,
and everything is automatically wired together so only intended calls are allowed.

In this tutorial, we will:

- Deploy a server pod, and two client pods calling it.
- Declare that the first client intends to call the server.
- See that a network policy was autogenerated to allow just that, and block the (undeclared) calls from the other client.

## Make sure you have a cluster that supports network policies
Before you start, you need a Kubernetes cluster with a [CNI](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/) that supports [NetworkPolicies](https://kubernetes.io/docs/concepts/services-networking/network-policies/).

{@include: ../_common/cluster-setup.md}

## Install Otterize

:::note
You can skip this section if Otterize is already installed in your cluster.
:::

{@include: ../_common/install-otterize.md}


## Deploy the server, client, client-other

Our simple example consists of three pods: an HTTP server and two clients that call it.

<details>
<summary>Expand to see the example YAML files</summary>
<Tabs>

<TabItem value="namespace.yaml" label="namespace.yaml" default>

```yaml
{@include: ../../static/code-examples/automate-network-policies/namespace.yaml}
```

</TabItem>

<TabItem value="server.yaml" label="server.yaml" default>

```yaml
{@include: ../../static/code-examples/automate-network-policies/server-deployment.yaml}
---
{@include: ../../static/code-examples/automate-network-policies/server-service.yaml}
```

</TabItem>
<TabItem value="client.yaml" label="client.yaml" default>

```yaml
{@include: ../../static/code-examples/automate-network-policies/client-deployment.yaml}
```

</TabItem>
<TabItem value="client-other.yaml" label="client-other.yaml" default>

```yaml
{@include: ../../static/code-examples/automate-network-policies/client-other-deployment.yaml}
```

</TabItem>

</Tabs>
</details>

1. Deploy the two clients and the server in their namespace using `kubectl`:

    ```shell
    kubectl apply -f https://docs.otterize.com/code-examples/automate-network-policies/all.yaml
    ```

    <details>
    <summary>Optional: check deployment status</summary>
    Check that the client and server pods were deployed

    ```bash
    kubectl get pods -n otterize-tutorial-npol
    ```
    You should see
    ```
    NAME                           READY   STATUS    RESTARTS   AGE
    client-596bcb48d5-pnjxc        1/1     Running   0          8s
    client-other-f56d65d7f-z2wg2   1/1     Running   0          8s
    server-6bb4784ccc-wtz7f        1/1     Running   0          8s
    ```
    </details>

Let's monitor both client attempts to call the server with additional terminal windows,
so we can see the effects of our changes in real time.

2. **Open a new terminal window [client]** and tail the client log:
    ```bash
    kubectl logs -f --tail 1 -n otterize-tutorial-npol deploy/client
    ```
    At this point the client should be able to communicate with the server:
    ```
    Calling server...
    HTTP/1.1 200 OK
    accept-ranges: bytes
    cache-control: max-age=3600
    last-modified: Mon, 03 Oct 2022 10:29:04 GMT
    etag: W/"3557515-49-2022-10-03T10:29:04.343Z"
    content-length: 49
    content-type: text/html; charset=UTF-8
    Date: Mon, 03 Oct 2022 10:30:51 GMT
    Connection: keep-alive
    Keep-Alive: timeout=5

    Hi, I am the server, you called, may I help you?
    ```

3. **Open another terminal window [client-other]** and tail the client-other log:
    ```bash
    kubectl logs -f --tail 1 -n otterize-tutorial-npol deploy/client-other
    ```
    At this point the client should be able to communicate with the server:
    ```
    Calling server...
    HTTP/1.1 200 OK
    accept-ranges: bytes
    cache-control: max-age=3600
    last-modified: Mon, 03 Oct 2022 10:29:04 GMT
    etag: W/"3557515-49-2022-10-03T10:29:04.343Z"
    content-length: 49
    content-type: text/html; charset=UTF-8
    Date: Mon, 03 Oct 2022 10:30:51 GMT
    Connection: keep-alive
    Keep-Alive: timeout=5

    Hi, I am the server, you called, may I help you?
    ```

## Apply intents
We will now declare that the **client** intends to call the **server**.
When the intents YAML is applied, creating a custom resource of type `ClientIntents`,
Otterize will add a network policy to allow the intended calls
(**client** &rarr; **server**) and fail all unintended calls (e.g., **client-other** &rarr; **server**).

1. Here is the `intents.yaml` declaration of the client, which we will apply below:
```yaml
{@include: ../../static/code-examples/automate-network-policies/intents.yaml}
```
:::tip
Client intents are the cornerstone of [intent-based access control (IBAC)](https://otterize.com/ibac).
:::
   Keep an eye on the logs being tailed in the **[client-other]** terminal window,
   and apply this `intents.yaml` file in your **main terminal window** using:
   ```shell
   kubectl apply -f https://docs.otterize.com/code-examples/automate-network-policies/intents.yaml
   ```
2. You should quickly see in the **[client-other]** terminal that it times out when calling the server,
   as expected since it didn't declare its intents:
   ```bash
   Calling server...
   HTTP/1.1 200 OK
   accept-ranges: bytes
   cache-control: max-age=3600
   last-modified: Mon, 03 Oct 2022 10:29:04 GMT
   etag: W/"3557515-49-2022-10-03T10:29:04.343Z"
   content-length: 49
   content-type: text/html; charset=UTF-8
   Date: Mon, 03 Oct 2022 10:41:14 GMT
   Connection: keep-alive
   Keep-Alive: timeout=5

   Hi, I am the server, you called, may I help you?  # <- before applying the intents file
   # highlight-start
   Calling server...                                 # <- after applying the intents file
   curl timed out
   Calling server...
   curl timed out
   # highlight-end
   ```
:::info
If the client isn't timing out, then the installed CNI plugin likely does not support network policies.
Consult the docs for your Kubernetes distribution or head back to the [Calico installation section](#make-sure-you-have-a-cni-network-plugin) to install one.
For example, Minikube does not start by default with a CNI that supports network policies
but you can ask it to start with one that does, such as Calico.
:::

3. And in the **[client]** terminal you should see that calls go through, as expected since they were declared:
   ```bash
   Calling server...
   HTTP/1.1 200 OK
   accept-ranges: bytes
   cache-control: max-age=3600
   last-modified: Mon, 03 Oct 2022 10:29:04 GMT
   etag: W/"3557515-49-2022-10-03T10:29:04.343Z"
   content-length: 49
   content-type: text/html; charset=UTF-8
   Date: Mon, 03 Oct 2022 10:41:14 GMT
   Connection: keep-alive
   Keep-Alive: timeout=5

   Hi, I am the server, you called, may I help you?
   ```
4. You should also see that a new network policy was created:
   ```bash
   kubectl get NetworkPolicies -n otterize-tutorial-npol
   ```
   will output:
   ```
   NAME                                           POD-SELECTOR                                         AGE
   access-to-server-from-otterize-tutorial-npol   otterize/server=server-otterize-tutorial-np-7e16db   6s
   default-deny-ingress                           <none>                                               28s
   ```
:::tip Done!
Otterize did its job of both protecting *and* allowing intended access.
:::
## What did we accomplish?

- Controlling access through network policies no longer means touching network policies at all.

- Clients simply declare what they need to access with their intents files.

- The next `kubectl apply` ensures that network policies automatically reflect the intended pod-to-pod access.


<details>
<summary>Expand to see what happened behind the scenes</summary>

Otterize generated a specific network policy on the ingress of the pods of a server, allowing the server to
be accessed by the pods of a client. Otterize uses labels to define the network policy and associate it
with a server in a namespace and a client in a namespace, as follows:
1. The server's pods are given a label `otterize/server` whose value uniquely represents that server.
   The network policy stipulates that it applies to the ingress of server pods with this label.
2. The client's pods are given a label `otterize/access-...` derived from the server's unique `otterize/server` value.
   The network policy stipulates that only client pods with this matching label can access the server.
3. The client's namespace is given a label `otterize/namespace-name` whose value is the namespace of the client.
   The network policy stipulates that only client pods whose namespaces have this label can access the server.
   This is used to allow cross-namespace intents.

Otterize saved us from doing all this work by simply declaring the client's intents in `intents.yaml`,
while the appropriate network policies were managed automatically behind the scenes.

Further information about network policies and Otterize can be found
[here](/guides/k8s-ibac-via-network-policies/deeper-dive).
</details>

:::tip Bonus tutorial
Try to create an intents file yourself for **client-other**, and apply it to allow this other client to call the server.
:::

## What's next

- See the [guide for IBAC with network policies](/guides/k8s-ibac-via-network-policies/) to explore intents-based access control in a larger example or with your own set of services.
- Get started with the [Otterize network mapper](/quick-tutorials/k8s-network-mapper) to help you bootstrap intents files
  for use in IBAC.

## Teardown

To remove the deployed examples run:

```bash
kubectl delete namespace otterize-tutorial-npol
```