---
sidebar_position: 1
title: IBAC in Kubernetes via network policies
---

One of the easiest ways to realize [intent-based access control](/intent-based-access-control) in Kubernetes is by leveraging network policies.

Network policies are built into Kubernetes itself, and while their enforcement is not, all that's required
is a Kubernetes CNI network plugin; most Kubernetes clusters either have a CNI installed or can add one easily.

Enforcement through network policies is limited to pod-to-pod access control, not finer-grained access control:
you cannot limit access to certain paths and methods in HTTP, or to certain topics and operations in Kafka, for example.
On the other hand, implementing network policy access control requires no code changes so it might be a great
first step, and it might entirely satisfy some use cases.

Authoring network policies manually can be complicated and tedious, especially because you need to think at a network
level vs functionally, and because you need to carefully coordinate labels across separate pod (e.g. deployment) resources
and network policy resources to achieve any specific outcome.

Of course, Otterize eliminates all of that. Let's see how.

## Choose a Kubernetes cluster and services

You can use this guide with your own set of services, e.g. first in a Kubernetes cluster running dev or lab services,
and eventually in a staging or production cluster. You'll need admin access.

Alternatively, you can start with services from our reference lab,
which is based on the [Google microservices demo](https://github.com/GoogleCloudPlatform/microservices-demo)
simulating an e-commerce application. You'll deploy these into any Kubernetes cluster to which you have admin access.

For the sake of illustration, we'll refer to the reference lab example in this guide. But if you're using
your own services, just apply the same steps and adjust the particulars to your needs.

### Reference lab example

The reference e-commerce application architecture is as follows
![Demo e-commerce](https://github.com/GoogleCloudPlatform/microservices-demo/raw/main/docs/img/architecture-diagram.png)

By default, any service is allowed to call any other service, though their code only makes the calls marked with arrows
&mdash; i.e. *the arrows indicate the intended traffic*.

The purpose of IBAC is to *automatically turn those design-time intents
into runtime constraints*: all calls declared to be intended will be allowed,
while all other calls &mdash; e.g. ones made by mistake, or ones due to
security breaches &mdash; will be blocked.

### Deploying the reference lab

Create a namespace to hold the services, and deploy them:
```bash
kubectl create namespace otterize-ecom-demo
kubectl apply -n otterize-ecom-demo -f https://raw.githubusercontent.com/GoogleCloudPlatform/microservices-demo/main/release/kubernetes-manifests.yaml
```
<details>
  <summary>Optional: check that the lab was deployed...</summary>
  <div>


To see all the pods in the lab:
```bash
kubectl get pods -n otterize-ecom-demo
```
The pods should all be ready and running:
```bash
NAME                                     READY   STATUS    RESTARTS   AGE
adservice-694f4ff98-cz4nn                1/1     Running   0          23m
cartservice-85f8bc44fd-45cbk             1/1     Running   0          23m
checkoutservice-8fc47bbbd-9lhfv          1/1     Running   0          23m
currencyservice-597bdf576b-8hftc         1/1     Running   0          23m
emailservice-d5c6f74dd-qlwc4             1/1     Running   0          23m
frontend-7ffbf49884-j9rhz                1/1     Running   0          23m
loadgenerator-65779994db-tgdxk           1/1     Running   0          23m
paymentservice-76b9c8b87d-ktfcd          1/1     Running   0          23m
productcatalogservice-6969d4f5fd-xdw99   1/1     Running   0          23m
recommendationservice-58798d5c8-2f4rz    1/1     Running   0          23m
redis-cart-6f65887b5d-xwpz5              1/1     Running   0          23m
shippingservice-ff5f4d7d-qcjw8           1/1     Running   0          23m
```


  </div>
</details>

### Let's go shop in the lab!

To get the externally-accessible URL where your demo front end is available, run:
```bash
kubectl get service -n otterize-ecom-demo frontend-external -o json | jq -r '.status.loadBalancer.ingress[0].hostname'
```
The result should be similar to (if running on AWS EKS):
```
a11843075fd254f8099a986467098647-1889474685.us-east-1.elb.amazonaws.com
```
Go ahead and browse to the URL above to "shop" and get a feel for the reference lab's behavior.
(The URL might take some time to populate across DNS servers. Note that we are accessing an HTTP and not an HTTPS website.)

<img src="https://github.com/GoogleCloudPlatform/microservices-demo/raw/main/docs/img/online-boutique-frontend-1.png" />

## Install Otterize into your Kubernetes
To apply intents on an existing cluster you will need to install Otterize with the network policies
option enabled. Follow the [instructions](/guides/k8s-installation) to install Otterize or
install only the [network policy components](/guides/k8s-installation#network-policies-only) for Otterize.

## Declare some intents

Recall the simple premise of IBAC: *clients* need to declare the calls they need to make, and that's it.
(After all, that's all the service developer should know: the calls their code makes.)
*Server* access control happens automatically.

In this guide, we'll roll out intent-based access control **gradually**. In most cases this will be better than
imposing that absolutely every service-to-service call must be declared or it will be blocked, because it takes
time for teams to adopt and gain confidence in any new approach or automation.

Network policies are great for gradual rollout:
1. Because they require no code changes (e.g. no new credentials to access secured services),
there's less friction and risk.
2. Second, by default, if a pod has no ingress-type
network policy applied, then it allows all incoming calls; as soon as it has *any* ingress-type network policy,
then all incoming calls *require* a network policy. So as soon as a client declares its intent to call a server,
and Otterize automatically adds a network policy from that client to that server, the server is now protected
from *any* undeclared calls.

### Start with one client's intents

So, let's pick a service that accepts calls (i.e. a server), and a client that intends to call it, and declare
that client's intent. When we `kubectl apply` that intent, we'll expect that the client can still call that server,
but all other callers of that server will be blocked. All other *servers* will be untouched &mdash; it's a *gradual* rollout
rather than trying to protect all servers at once.

Here's what it looks like for the reference lab. If you're using your own services, adjust accordingly.

<!-- FIXME
Show the lab again, but now with a circle overlay or other color coding showing the server that will be protected,
the client that will declare its intent to call that server and still go through,
and the client that will now be blocked (until it declares its intent too).
--->

- The `productcatalogservice` *serves* product information;
  - The `checkoutservice` needs to *call it* when checking out;
  - The `recommendationservice` needs to call it to generate recommendations.

Here's the intents file of the `recommendationservice` (remember to adjust if you have a different service):
```yaml
{@include: ../../../static/code-examples/lab/recommendationservice-productcatalogservice.yaml}
```
1. Let's apply this intents file, as a developer or a CI/CD process would do:
    ```bash
    kubectl apply -f https://docs.otterize.com/code-examples/lab/recommendationservice-productcatalogservice.yaml
    ```

2. And check in on our lab by adding an item to your cart and placing an order.

    ![Place order](/resources/lab/place-order.png)
3. You will notice that the site hangs as the `checkoutservice` tries to call the `productcatalogservice` but is being blocked
   by the network policies set in the previous stage. When the `checkoutservice` times out you will see.
    ![Checkout service timed out](/resources/lab/checkoutservice-timeout.png)

### Add a second client's intents

Now let's add the intents file of the `checkoutservice` (remember to adjust if you have a different service):
```yaml
{@include: ../../../static/code-examples/lab/checkoutservice-productcatalogservice.yaml}
```

1. Again, apply it to see what happens when it declares its intents:
   ```bash
   kubectl apply -f https://docs.otterize.com/code-examples/lab/checkoutservice-productcatalogservice.yaml
   ```
2. Go ahead and place an order on the side, you will see all functions correctly.
    ![Order complete](/resources/lab/order-complete.png)
<!-- FIXME
Add updated lab image
-->

## Lather, rinse, repeat

That's pretty much all there is to it!

You can pick another service, and ask its clients to declare their intents. Once these are applied (in fact, once
any of them is applied), that service is protected from undeclared access from any other pod.

To help onboard services to this approach, you can bootstrap client intents files:
simply install the Otterize network mapper into some cluster where all the calls that should be happening are
actually happening, and watch as it detects them and generates a complete set of client intents files that
reflect all those calls.


<details>
  <summary>Optional bootstrapping exercise: </summary>
  <div>

To see the potential of the network mapper in bootstrapping IBAC, try this:
1. Run the network mapper while generating enough traffic in your cluster to capture all calls, and
      export them as intents files.
    ```bash
    otterize mapper export -n otterize-ecom-demo -o intents.yaml
    ```
    Or, if you're using the reference lab we've already done that for you:
    ```bash
    wget https://docs.otterize.com/code-examples/lab/intents.yaml
    ```
2. Create and apply a "default-deny-ingress" network policy in your cluster for the selected namespace;
   all pods will now have at least one ingress policy so *all* undeclared calls will be blocked.
   ```yaml
   {@include: ../../../static/code-examples/lab/default-deny-network-policy.yaml}
   ```
   if you're using the reference lab we've already done that for you:
   ```bash
   kubectl apply -f https://docs.otterize.com/code-examples/lab/default-deny-network-policy.yaml
   ```
3. See that most services are now blocked. For example, the reference lab will stop working.
4. Now apply all the intents you captured in the first step.
   ```bash
   kubectl apply -f intents.yaml
   ```
5. Your cluster should now roar back to life, fully functioning *and now secured*!


  </div>
</details>


FIXME: SUGGEST NEXT STEPS AND FINISH BELOW

## Practical notes

### Avoiding drift
