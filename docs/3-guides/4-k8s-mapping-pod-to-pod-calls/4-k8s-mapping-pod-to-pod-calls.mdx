---
title: Mapping pod-to-pod calls in Kubernetes
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

The network mapper allows you to map pod-to-pod traffic within your K8s cluster. This tutorial will guide you
through installing Otterize, mapping traffic and tracking changes.

## Make sure you have a Kubernetes cluster
Before you start, you need to have a Kubernetes cluster. Having a cluster with a [CNI](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/) that supports [NetworkPolicies](https://kubernetes.io/docs/concepts/services-networking/network-policies/) isn't required for this guide, but is recommended so that your cluster works with other guides.

{@include: ../_common/cluster-setup.md}

## Install the network mapper

{@include: ../../_common/install-otterize-network-mapper.md}

## Install the Otterize CLI

{@include: ../../_common/install-otterize-cli.md}

## Retrieving the network map

### Choose a Kubernetes cluster and services

You can use this guide with your own set of services, e.g. first in a Kubernetes cluster running dev or lab services,
and eventually in a staging or production cluster.

Alternatively, you can start with services from our reference lab,
which is based on the [Google microservices demo](https://github.com/GoogleCloudPlatform/microservices-demo)
simulating an e-commerce application. You'll deploy these into any Kubernetes cluster to which you have admin access.
The lab includes a load generator that simulates front-end user interactions, so as soon as you deploy it,
the various services start to call each other.

For the sake of illustration, we'll reference this lab example in this guide. But if you're using
your own services, just apply the same steps and adjust the particulars to your case.

### Reference lab example

The reference e-commerce application architecture is as follows:
![Demo e-commerce](https://github.com/GoogleCloudPlatform/microservices-demo/raw/main/docs/img/architecture-diagram.png)

The arrows indicate the calls which each service makes to other services. This is the traffic that will be
generated by the load generator and automatically "sniffed" by the network mapper to build up the map.

### Deploying the reference lab

Create a namespace to hold the services, and deploy them:
```bash
kubectl create namespace otterize-ecom-demo
kubectl apply -n otterize-ecom-demo -f https://docs.otterize.com/code-examples/microservices-demo/kubernetes-manifests.yml
```
<details>
<summary>Optional: check that the lab was deployed...</summary>
<div>

    To see all the pods in the lab:
    ```bash
    kubectl get pods -n otterize-ecom-demo
    ```
    The pods should all be ready and running:
    ```bash
    NAME                                     READY   STATUS    RESTARTS   AGE
    adservice-694f4ff98-cz4nn                1/1     Running   0          23m
    cartservice-85f8bc44fd-45cbk             1/1     Running   0          23m
    checkoutservice-8fc47bbbd-9lhfv          1/1     Running   0          23m
    currencyservice-597bdf576b-8hftc         1/1     Running   0          23m
    emailservice-d5c6f74dd-qlwc4             1/1     Running   0          23m
    frontend-7ffbf49884-j9rhz                1/1     Running   0          23m
    loadgenerator-65779994db-tgdxk           1/1     Running   0          23m
    paymentservice-76b9c8b87d-ktfcd          1/1     Running   0          23m
    productcatalogservice-6969d4f5fd-xdw99   1/1     Running   0          23m
    recommendationservice-58798d5c8-2f4rz    1/1     Running   0          23m
    redis-cart-6f65887b5d-xwpz5              1/1     Running   0          23m
    shippingservice-ff5f4d7d-qcjw8           1/1     Running   0          23m
    ```

</div>
</details>

:::tip
Once the lab is deployed, its load generator starts automatically and generates traffic that the network mapper
will pick up. We suggest you wait a minute or so before continuing to the next step,
so all services will have had a chance to make their calls and the network map will be complete.
:::

You can view mapped traffic by calling the CLI `list` or `export` commands.
The latter supports multiple output formats, namely `intents` (client intents files) and `json`.
The following shows the CLI output filtered for the namespace (`otterize-ecom-demo`)
of the reference lab we deployed above.

<Tabs>
  <TabItem value="list" label="List" default>

1. List the pod-to-pod network map built up ("sniffed") so far:

   ```shell
   otterize mapper list -n otterize-ecom-demo
   ```
2. You should see the rich network map of the reference e-commerce lab we deployed above:
   ```shell
   cartservice in namespace otterize-ecom-demo calls:
     - redis-cart
   checkoutservice in namespace otterize-ecom-demo calls:
     - cartservice
     - currencyservice
     - emailservice
     - paymentservice
     - productcatalogservice
     - shippingservice
   frontend in namespace otterize-ecom-demo calls:
     - adservice
     - cartservice
     - checkoutservice
     - currencyservice
     - productcatalogservice
     - recommendationservice
     - shippingservice
   loadgenerator in namespace otterize-ecom-demo calls:
     - frontend
   recommendationservice in namespace otterize-ecom-demo calls:
     - productcatalogservice
   ```

</TabItem>
  <TabItem value="intents" label="Export as intents" default>

1. Export as YAML client intents (the default format) the pod-to-pod network map built up so far:

   ```shell
   otterize mapper export -n otterize-ecom-demo
   ```
2. The result is a long YAML file stream that concatenates individual YAML intents documents,
one for each service that makes calls to other services:
   ```yaml
   apiVersion: k8s.otterize.com/v1alpha1
   kind: ClientIntents
   metadata:
     name: cartservice
     namespace: otterize-ecom-demo
   spec:
     service:
       name: cartservice
     calls:
       - name: redis-cart
         type: http
   ---
   apiVersion: k8s.otterize.com/v1alpha1
   kind: ClientIntents
   metadata:
     name: checkoutservice
     namespace: otterize-ecom-demo
   spec:
     service:
       name: checkoutservice
     calls:
       - name: cartservice
         type: http
       - name: currencyservice
         type: http
       - name: emailservice
         type: http
       - name: paymentservice
         type: http
       - name: productcatalogservice
         type: http
       - name: shippingservice
         type: http
   ---
   apiVersion: k8s.otterize.com/v1alpha1
   kind: ClientIntents
   metadata:
     name: frontend
     namespace: otterize-ecom-demo
   spec:
     service:
       name: frontend
     calls:
       - name: adservice
         type: http
       - name: cartservice
         type: http
       - name: checkoutservice
         type: http
       - name: currencyservice
         type: http
       - name: productcatalogservice
         type: http
       - name: recommendationservice
         type: http
       - name: shippingservice
         type: http
   ---
   apiVersion: k8s.otterize.com/v1alpha1
   kind: ClientIntents
   metadata:
     name: loadgenerator
     namespace: otterize-ecom-demo
   spec:
     service:
       name: loadgenerator
     calls:
       - name: frontend
         type: http
   ---
   apiVersion: k8s.otterize.com/v1alpha1
   kind: ClientIntents
   metadata:
     name: recommendationservice
     namespace: otterize-ecom-demo
   spec:
     service:
       name: recommendationservice
     calls:
       - name: productcatalogservice
         type: http
   ```

Note that you can also export a collection of individual YAML files, suitable for moving to the repos where their corresponding
client codes live, so they can be evolved along with the code. To do this, use
`otterize mapper export -n otterize-ecom-demo --output-type dir`

</TabItem>
  <TabItem value="json" label="Export as JSON">

1. Export as JSON the pod-to-pod network map built up so far:

   ```shell
   otterize mapper export -n otterize-ecom-demo --format json
   ```
2. The result shows the network map of the reference lab in JSON format:
   ```json
   [
     {
       "kind": "ClientIntents",
       "apiVersion": "k8s.otterize.com/v1alpha1",
       "metadata": {
         "name": "cartservice",
         "namespace": "otterize-ecom-demo",
         "creationTimestamp": null
       },
       "spec": {
         "service": {
           "name": "cartservice"
         },
         "calls": [
           {
             "type": "http",
             "name": "redis-cart"
           }
         ]
       }
     },
     {
       "kind": "ClientIntents",
       "apiVersion": "k8s.otterize.com/v1alpha1",
       "metadata": {
         "name": "checkoutservice",
         "namespace": "otterize-ecom-demo",
         "creationTimestamp": null
       },
       "spec": {
         "service": {
           "name": "checkoutservice"
         },
         "calls": [
           {
             "type": "http",
             "name": "cartservice"
           },
           {
             "type": "http",
             "name": "currencyservice"
           },
           {
             "type": "http",
             "name": "emailservice"
           },
           {
             "type": "http",
             "name": "paymentservice"
           },
           {
             "type": "http",
             "name": "productcatalogservice"
           },
           {
             "type": "http",
             "name": "shippingservice"
           }
         ]
       }
     },
     {
       "kind": "ClientIntents",
       "apiVersion": "k8s.otterize.com/v1alpha1",
       "metadata": {
         "name": "frontend",
         "namespace": "otterize-ecom-demo",
         "creationTimestamp": null
       },
       "spec": {
         "service": {
           "name": "frontend"
         },
         "calls": [
           {
             "type": "http",
             "name": "adservice"
           },
           {
             "type": "http",
             "name": "cartservice"
           },
           {
             "type": "http",
             "name": "checkoutservice"
           },
           {
             "type": "http",
             "name": "currencyservice"
           },
           {
             "type": "http",
             "name": "productcatalogservice"
           },
           {
             "type": "http",
             "name": "recommendationservice"
           },
           {
             "type": "http",
             "name": "shippingservice"
           }
         ]
       }
     },
     {
       "kind": "ClientIntents",
       "apiVersion": "k8s.otterize.com/v1alpha1",
       "metadata": {
         "name": "loadgenerator",
         "namespace": "otterize-ecom-demo",
         "creationTimestamp": null
       },
       "spec": {
         "service": {
           "name": "loadgenerator"
         },
         "calls": [
           {
             "type": "http",
             "name": "frontend"
           }
         ]
       }
     },
     {
       "kind": "ClientIntents",
       "apiVersion": "k8s.otterize.com/v1alpha1",
       "metadata": {
         "name": "recommendationservice",
         "namespace": "otterize-ecom-demo",
         "creationTimestamp": null
       },
       "spec": {
         "service": {
           "name": "recommendationservice"
         },
         "calls": [
           {
             "type": "http",
             "name": "productcatalogservice"
           }
         ]
       }
     }
   ]
   ```

</TabItem>
</Tabs>

:::tip
For a complete list of Otterize network mapper capabilities,
refer to the [CLI command reference](/cli/#network-mapper).

For example, we've already seen how to filter by namespace, using `otterize mapper list -n <namespace>`.

You might also try to reset the network map with `otterize mapper reset`, then quickly run `otterize mapper list`
before the load generator runs again, and see the smaller map generated from the more limited traffic observed.
:::

## Track network map changes over time

By continuing to run the network mapper, resetting if desired to clear out traffic that will no longer occur,
and listing or exporting to files, you can track changes to the network map over time.
We call this process "**Sniff&Diff**".

1. Let's save the list of the current network map into a file, that will serve as a baseline:
   ```shell
   otterize mapper list -n otterize-ecom-demo > intents-original.txt
   ```

2. Now let's add a new service, `testingservice`, that calls the `frontend` over HTTP every couple of seconds:
   ```shell
   kubectl apply -n otterize-ecom-demo -f https://docs.otterize.com/code-examples/network-mapper/testingservice-to-frontend-deployment.yaml
   ```

<details>
<summary>Check that the new pod was deployed</summary>

```bash
    kubectl get pods -n otterize-ecom-demo -l app=testingservice
```
You should see
```
NAME                               READY   STATUS    RESTARTS   AGE
testingservice-7b8cc77c67-9ksk8   1/1     Running   0          3m3s
```
</details>

3. Will the network mapper pick it up? Let's wait a few seconds and list the network map now:
   ```shell
   otterize mapper list -n otterize-ecom-demo
   ```

   You should now see that the list is a bit longer. It now includes calls between the testing service and the frontend:
   ```shell
   cartservice in namespace otterize-ecom-demo calls:
     - redis-cart
   checkoutservice in namespace otterize-ecom-demo calls:
     - cartservice
     - currencyservice
     - emailservice
     - paymentservice
     - productcatalogservice
     - shippingservice
   frontend in namespace otterize-ecom-demo calls:
     - adservice
     - cartservice
     - checkoutservice
     - currencyservice
     - productcatalogservice
     - recommendationservice
     - shippingservice
   loadgenerator in namespace otterize-ecom-demo calls:
     - frontend
   recommendationservice in namespace otterize-ecom-demo calls:
     - productcatalogservice
   # highlight-start
   testingservice in namespace otterize-ecom-demo calls:
     - frontend
   # highlight-end
   ```
5. We can also compare both outputs to see the difference. Start by saving the updated list to a file:
   ```bash
   otterize mapper list -n otterize-ecom-demo > intents-updated.txt
   ```
6. Now compare the original file with the updated file using:
   ```bash
   diff -y intents-original.txt intents-updated.txt;echo
   ```
   Note the new network map entry identified on the lower right, showing the testing service calling the frontend:
   ```bash
   cartservice in namespace otterize-ecom-demo calls:              cartservice in namespace otterize-ecom-demo calls:
     - redis-cart                                                    - redis-cart
   checkoutservice in namespace otterize-ecom-demo calls:          checkoutservice in namespace otterize-ecom-demo calls:
     - cartservice                                                   - cartservice
     - currencyservice                                               - currencyservice
     - emailservice                                                  - emailservice
     - paymentservice                                                - paymentservice
     - productcatalogservice                                         - productcatalogservice
     - shippingservice                                               - shippingservice
   frontend in namespace otterize-ecom-demo calls:                 frontend in namespace otterize-ecom-demo calls:
     - adservice                                                     - adservice
     - cartservice                                                   - cartservice
     - checkoutservice                                               - checkoutservice
     - currencyservice                                               - currencyservice
     - productcatalogservice                                         - productcatalogservice
     - recommendationservice                                         - recommendationservice
     - shippingservice                                               - shippingservice
   loadgenerator in namespace otterize-ecom-demo calls:            loadgenerator in namespace otterize-ecom-demo calls:
     - frontend                                                      - frontend
   recommendationservice in namespace otterize-ecom-demo calls:    recommendationservice in namespace otterize-ecom-demo calls:
     - productcatalogservice                                         - productcatalogservice
                                                                 > testingservice in namespace otterize-ecom-demo calls:
                                                                 >   - frontend
    ```


## Which calls are picked up by the mapper
The Otterize network mapper creates a map of in-cluster traffic by observing DNS traffic as well as
active connections (similarly to `netstat`), tracing the IP addresses observed back to the pods that called or
were called, and walking up the ownership tree of each pod until reaching the root object.

To learn more, see the [network mapper detailed documentation](/components/network-mapper).

<!-- FIXME
:::tip
Checkout this blog by Evyatar Meged about how we implemented this feature.
:::
-->

## What's next

One of the outputs of the network mapper is a set of intents that reflect the observed traffic.
The mapper doesn't look at the types and contents of the calls, so the intents won't have granular information
beyond what service calls what service. But it's a pretty good way to bootstrap intents files and get
going with intent-based access control.

Take a look at the **intents** tab in the section called [Show mapped traffic](#show-mapped-traffic).
With these intents we can then automatically control pod-to-pod access using Kubernetes network policies:
in other words, these intents create network policies that reflect the mapped traffic, and as you
evolve the intents and apply them, the network policies will always reflect the intents.

To see this in action,
follow the guide for implementing [IBAC via network policies](/guides/k8s-ibac-via-network-policies/).
It concludes with an exercise that uses your mapped traffic as initial intents files and demonstrates
the automatic generation of network policies to make sure only intended traffic is allowed.


## Design note

* The network mapper is designed for situations where pods use Kubernetes DNS for service discovery.

### Teardown

To remove the deployed resources run:

```bash
kubectl delete namespace otterize-ecom-demo
```