"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5079],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>k});var a=n(7294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,l=function(e,t){if(null==e)return{};var n,a,l={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,l=e.mdxType,o=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=c(n),m=l,k=u["".concat(s,".").concat(m)]||u[m]||d[m]||o;return n?a.createElement(k,r(r({ref:t},p),{},{components:n})):a.createElement(k,r({ref:t},p))}));function k(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var o=n.length,r=new Array(o);r[0]=m;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[u]="string"==typeof e?e:l,r[1]=i;for(var c=2;c<o;c++)r[c]=n[c];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},5162:(e,t,n)=>{n.d(t,{Z:()=>r});var a=n(7294),l=n(6010);const o={tabItem:"tabItem_Ymn6"};function r(e){let{children:t,hidden:n,className:r}=e;return a.createElement("div",{role:"tabpanel",className:(0,l.Z)(o.tabItem,r),hidden:n},t)}},4866:(e,t,n)=>{n.d(t,{Z:()=>w});var a=n(7462),l=n(7294),o=n(6010),r=n(2466),i=n(6550),s=n(1980),c=n(7392),p=n(12);function u(e){return function(e){return l.Children.map(e,(e=>{if(!e||(0,l.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:l}}=e;return{value:t,label:n,attributes:a,default:l}}))}function d(e){const{values:t,children:n}=e;return(0,l.useMemo)((()=>{const e=t??u(n);return function(e){const t=(0,c.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function m(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function k(e){let{queryString:t=!1,groupId:n}=e;const a=(0,i.k6)(),o=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,s._X)(o),(0,l.useCallback)((e=>{if(!o)return;const t=new URLSearchParams(a.location.search);t.set(o,e),a.replace({...a.location,search:t.toString()})}),[o,a])]}function h(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,o=d(e),[r,i]=(0,l.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!m({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:o}))),[s,c]=k({queryString:n,groupId:a}),[u,h]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[a,o]=(0,p.Nk)(n);return[a,(0,l.useCallback)((e=>{n&&o.set(e)}),[n,o])]}({groupId:a}),g=(()=>{const e=s??u;return m({value:e,tabValues:o})?e:null})();(0,l.useLayoutEffect)((()=>{g&&i(g)}),[g]);return{selectedValue:r,selectValue:(0,l.useCallback)((e=>{if(!m({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);i(e),c(e),h(e)}),[c,h,o]),tabValues:o}}var g=n(2389);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function y(e){let{className:t,block:n,selectedValue:i,selectValue:s,tabValues:c}=e;const p=[],{blockElementScrollPositionUntilNextRender:u}=(0,r.o5)(),d=e=>{const t=e.currentTarget,n=p.indexOf(t),a=c[n].value;a!==i&&(u(t),s(a))},m=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const n=p.indexOf(e.currentTarget)+1;t=p[n]??p[0];break}case"ArrowLeft":{const n=p.indexOf(e.currentTarget)-1;t=p[n]??p[p.length-1];break}}t?.focus()};return l.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":n},t)},c.map((e=>{let{value:t,label:n,attributes:r}=e;return l.createElement("li",(0,a.Z)({role:"tab",tabIndex:i===t?0:-1,"aria-selected":i===t,key:t,ref:e=>p.push(e),onKeyDown:m,onClick:d},r,{className:(0,o.Z)("tabs__item",f.tabItem,r?.className,{"tabs__item--active":i===t})}),n??t)})))}function b(e){let{lazy:t,children:n,selectedValue:a}=e;const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=o.find((e=>e.props.value===a));return e?(0,l.cloneElement)(e,{className:"margin-top--md"}):null}return l.createElement("div",{className:"margin-top--md"},o.map(((e,t)=>(0,l.cloneElement)(e,{key:t,hidden:e.props.value!==a}))))}function N(e){const t=h(e);return l.createElement("div",{className:(0,o.Z)("tabs-container",f.tabList)},l.createElement(y,(0,a.Z)({},e,t)),l.createElement(b,(0,a.Z)({},e,t)))}function w(e){const t=(0,g.Z)();return l.createElement(N,(0,a.Z)({key:String(t)},e))}},8217:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>k,frontMatter:()=>i,metadata:()=>c,toc:()=>u});var a=n(7462),l=(n(7294),n(3905)),o=n(4866),r=n(5162);const i={sidebar_position:4,title:"Kafka access automation using Otterize Cloud mTLS"},s=void 0,c={unversionedId:"quickstart/access-control/k8s-kafka-mtls",id:"quickstart/access-control/k8s-kafka-mtls",title:"Kafka access automation using Otterize Cloud mTLS",description:"This tutorial will walk you through declaring and applying intents to easily secure access to Kafka running inside a Kubernetes cluster, automating the management of Kafka ACLs, and the generation and deployment of certificates for mTLS between Kafka and its clients using Otterize Cloud as the certificate provider.",source:"@site/docs/quickstart/access-control/k8s-kafka-mtls.mdx",sourceDirName:"quickstart/access-control",slug:"/quickstart/access-control/k8s-kafka-mtls",permalink:"/quickstart/access-control/k8s-kafka-mtls",draft:!1,editUrl:"https://github.com/otterize/docs/edit/main/docs/quickstart/access-control/k8s-kafka-mtls.mdx",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,title:"Kafka access automation using Otterize Cloud mTLS"},sidebar:"docSidebar",previous:{title:"Istio AuthorizationPolicy automation",permalink:"/quickstart/access-control/k8s-istio-authorization-policies"},next:{title:"Kafka access automation using cert-manager mTLS",permalink:"/quickstart/access-control/k8s-kafka-mtls-cert-manager"}},p={},u=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Prepare a Kubernetes cluster",id:"prepare-a-kubernetes-cluster",level:3},{value:"Install Otterize",id:"install-otterize",level:3},{value:"Install Otterize OSS, connected to Otterize Cloud",id:"install-otterize-oss-connected-to-otterize-cloud",level:4},{value:"Configure the access graph in Otterize Cloud to only show Kafka authorization status",id:"configure-the-access-graph-in-otterize-cloud-to-only-show-kafka-authorization-status",level:4},{value:"Install Kafka",id:"install-kafka",level:2},{value:"Configure Otterize to manage Kafka access",id:"configure-otterize-to-manage-kafka-access",level:2},{value:"Deploy clients",id:"deploy-clients",level:2},{value:"Apply intents",id:"apply-intents",level:2},{value:"Turn on protection",id:"turn-on-protection",level:2},{value:"What did we accomplish?",id:"what-did-we-accomplish",level:2},{value:"One-time setups",id:"one-time-setups",level:3},{value:"Per-client setups",id:"per-client-setups",level:3},{value:"Teardown",id:"teardown",level:2}],d={toc:u},m="wrapper";function k(e){let{components:t,...i}=e;return(0,l.kt)(m,(0,a.Z)({},d,i,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("p",null,"This tutorial will walk you through declaring and applying intents to easily secure access to Kafka running inside a Kubernetes cluster, automating the management of ",(0,l.kt)("a",{parentName:"p",href:"https://docs.confluent.io/platform/current/kafka/authorization.html"},"Kafka ACLs"),", and the generation and deployment of certificates for mTLS between Kafka and its clients using Otterize Cloud as the certificate provider."),(0,l.kt)("p",null,"If you prefer to generate certificates using ",(0,l.kt)("a",{parentName:"p",href:"https://cert-manager.io"},(0,l.kt)("inlineCode",{parentName:"a"},"cert-manager")),", try ",(0,l.kt)("a",{parentName:"p",href:"/quickstart/access-control/k8s-kafka-mtls-cert-manager"},"the tutorial for cert-manager"),"."),(0,l.kt)("p",null,"In this tutorial, we will:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Deploy Otterize with network policy enforcement disabled to focus on Kafka ACL enforcement"),(0,l.kt)("li",{parentName:"ul"},"Deploy a Kafka broker with 2 topics, and two clients that call these topics."),(0,l.kt)("li",{parentName:"ul"},"Declare that one client pod intends to access one of the topic."),(0,l.kt)("li",{parentName:"ul"},"Enable protection for this Kafka broker."),(0,l.kt)("li",{parentName:"ul"},"See that an ACL was auto-generated to allow just that, while blocking calls to that topic from the other client.")),(0,l.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,l.kt)("h3",{id:"prepare-a-kubernetes-cluster"},"Prepare a Kubernetes cluster"),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Expand for cluster setup instructions"),(0,l.kt)("p",null,"Before you start, you'll need a Kubernetes cluster."),(0,l.kt)("p",null,"Below are instructions for setting up a Kubernetes cluster with network policies.\nIf you don't have a cluster already, we recommend starting out with a Minikube cluster."),(0,l.kt)(o.Z,{groupId:"cni",mdxType:"Tabs"},(0,l.kt)(r.Z,{value:"minikube",label:"Minikube",mdxType:"TabItem"},(0,l.kt)("p",null,"If you don't have the Minikube CLI, first ",(0,l.kt)("a",{parentName:"p",href:"https://minikube.sigs.k8s.io/docs/start/"},"install it"),". "),(0,l.kt)("p",null,"Then start your Minikube cluster with Calico, in order to enforce network policies."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"minikube start --cpus=4 --memory 4096 --disk-size 32g --cni=calico\n")),(0,l.kt)("p",null,"The increased CPU, memory and disk resource allocations are required to be able to deploy the ecommerce app used in the visual tutorials successfully.")),(0,l.kt)(r.Z,{value:"gke",label:"Google GKE",mdxType:"TabItem"},(0,l.kt)("a",{href:"https://cloud.google.com/kubernetes-engine/docs/how-to/network-policy#gcloud"},"Visit the official documentation"),", or follow the instructions below:",(0,l.kt)(o.Z,{mdxType:"Tabs"},(0,l.kt)(r.Z,{value:"cli",label:"gcloud CLI",mdxType:"TabItem"},(0,l.kt)("p",null,"To use the gcloud CLI for this tutorial, first ",(0,l.kt)("a",{parentName:"p",href:"https://cloud.google.com/sdk/docs/install"},"install")," and then\n",(0,l.kt)("a",{parentName:"p",href:"https://cloud.google.com/sdk/docs/initializing"},"initialize")," it."),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("em",{parentName:"strong"},"To enable network policy enforcement when creating a new cluster:"))),(0,l.kt)("p",null,"Run the following command:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"gcloud container clusters create CLUSTER_NAME --enable-network-policy --zone=ZONE\n")),(0,l.kt)("p",null,"(Replace ",(0,l.kt)("inlineCode",{parentName:"p"},"CLUSTER_NAME")," with the name of the new cluster and ",(0,l.kt)("inlineCode",{parentName:"p"},"ZONE")," with your zone.)"),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("em",{parentName:"strong"},"To enable network policy enforcement for an existing cluster, perform the following tasks:"))),(0,l.kt)("p",null,"Run the following command to enable the add-on:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"gcloud container clusters update CLUSTER_NAME --update-addons=NetworkPolicy=ENABLED\n")),(0,l.kt)("p",null,"(Replace ",(0,l.kt)("inlineCode",{parentName:"p"},"CLUSTER_NAME")," with the name of the cluster.)"),(0,l.kt)("p",null,"Then enable network policy enforcement on your cluster, re-creating your cluster's node pools with network policy enforcement enabled:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"gcloud container clusters update CLUSTER_NAME --enable-network-policy\n")),(0,l.kt)("p",null,"(Replace ",(0,l.kt)("inlineCode",{parentName:"p"},"CLUSTER_NAME")," with the name of the cluster.)")),(0,l.kt)(r.Z,{value:"console",label:"Console",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("em",{parentName:"strong"},"To enable network policy enforcement when creating a new cluster:"))),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Go to the Google Kubernetes Engine page in the Google Cloud console.\nThe remaining steps will appear automatically in the Google Cloud console.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"On the Google Kubernetes Engine page, click Create.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Configure your cluster as desired.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"From the navigation pane, under Cluster, click Networking.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Select the checkbox to Enable network policy.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Click Create."))),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("em",{parentName:"strong"},"To enable network policy enforcement for an existing cluster:"))),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Go to the Google Kubernetes Engine page in the Google Cloud console. The remaining steps will appear automatically in the Google Cloud console.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"In the cluster list, click the name of the cluster you want to modify.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Under Networking, in the Network policy field, click Edit network policy.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Select the checkbox to Enable network policy for master and click Save Changes.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Wait for your changes to apply, and then click Edit network policy again.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Select the checkbox to Enable network policy for nodes.")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Click Save Changes.")))))),(0,l.kt)(r.Z,{value:"eks",label:"AWS EKS",mdxType:"TabItem"},(0,l.kt)("p",null,"Starting August 29, 2023, ",(0,l.kt)("a",{parentName:"p",href:"https://aws.amazon.com/blogs/containers/amazon-vpc-cni-now-supports-kubernetes-network-policies"},"you can configure the built-in VPC CNI add-on to enable network policy support"),".\nTo spin up a new cluster, use the following ",(0,l.kt)("inlineCode",{parentName:"p"},"eksctl")," ",(0,l.kt)("inlineCode",{parentName:"p"},"ClusterConfig"),", and save it to a file called ",(0,l.kt)("inlineCode",{parentName:"p"},"cluster.yaml"),"."),(0,l.kt)("p",null,"Spin up the cluster using ",(0,l.kt)("inlineCode",{parentName:"p"},"eksctl create cluster -f cluster.yaml"),". This will spin up a cluster called ",(0,l.kt)("inlineCode",{parentName:"p"},"network-policy-demo")," in ",(0,l.kt)("inlineCode",{parentName:"p"},"us-west-2"),"."),(0,l.kt)("p",null,"The important bit is the configuration for the VPC CNI addon:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},'    configurationValues: |-\n       # highlight-next-line\n      enableNetworkPolicy: "true"\n')),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: network-policy-demo\n  version: "1.27"\n  region: us-west-2\n\niam:\n  withOIDC: true\n\nvpc:\n  clusterEndpoints:\n    publicAccess: true\n    privateAccess: true\n\naddons:\n  - name: vpc-cni\n    version: 1.14.0\n    attachPolicyARNs: #optional\n    - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy \n    configurationValues: |-\n       # highlight-next-line\n      enableNetworkPolicy: "true"\n  - name: coredns\n  - name: kube-proxy\n\nmanagedNodeGroups:\n  - name: x86-al2-on-demand\n    amiFamily: AmazonLinux2\n    instanceTypes: [ "m6i.xlarge", "m6a.xlarge" ]\n    minSize: 0\n    desiredCapacity: 2\n    maxSize: 6\n    privateNetworking: true\n    disableIMDSv1: true\n    volumeSize: 100\n    volumeType: gp3\n    volumeEncrypted: true\n    tags:\n      team: "eks"\n')),(0,l.kt)("p",null,"For guides that deploy the larger set of services, Kafka and ZooKeeper are also deployed, and you will also need the EBS CSI driver to accommodate their storage needs. ",(0,l.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/eks/latest/userguide/managing-ebs-csi.html"},"Follow the AWS guide for the EBS CSI add-on to do so."),"\nIf you're not using the VPC CNI, you can set up the Calico network policy controller using the following instructions:"),(0,l.kt)("a",{href:"https://docs.aws.amazon.com/eks/latest/userguide/calico.html"},"Visit the official documentation"),", or follow the instructions below:",(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Spin up an ",(0,l.kt)("a",{parentName:"li",href:"https://docs.aws.amazon.com/eks/latest/userguide/create-cluster.html"},"EKS cluster")," using the console, AWS CLI or ",(0,l.kt)("inlineCode",{parentName:"li"},"eksctl"),"."),(0,l.kt)("li",{parentName:"ol"},"Install Calico for network policy enforcement, without replacing the CNI:")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/v1.12.6/config/master/calico-operator.yaml\nkubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/v1.12.6/config/master/calico-crs.yaml\n"))),(0,l.kt)(r.Z,{value:"aks",label:"Azure AKS",mdxType:"TabItem"},(0,l.kt)("p",null,"You can set up an AKS cluster using this ",(0,l.kt)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/azure/aks/learn/quick-kubernetes-deploy-cli"},"guide"),"."),(0,l.kt)("p",null,"For network policy support, no setup is required: Azure AKS comes with a built-in network policy implementation called Azure Network Policy Manager. You can choose whether you'd like to use this option or Calico when you create a cluster."),(0,l.kt)("a",{href:"https://learn.microsoft.com/en-us/azure/aks/use-network-policies"}," Read more at the official documentation site"),"."))),(0,l.kt)("h3",{id:"install-otterize"},"Install Otterize"),(0,l.kt)("p",null,"You can now install Otterize in your cluster, and connect to Otterize Cloud. Connecting to Cloud lets you:"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},'See what\'s happening visually in your browser, through the "access graph".'),(0,l.kt)("li",{parentName:"ol"},"Generate certificates using the Otterize Cloud hosted service. If you prefer to generate certificates in-cluster, you can ",(0,l.kt)("a",{parentName:"li",href:"/quickstart/access-control/k8s-kafka-mtls-cert-manager"},"follow the tutorial for cert-manager"),".")),(0,l.kt)("h4",{id:"install-otterize-oss-connected-to-otterize-cloud"},"Install Otterize OSS, connected to Otterize Cloud"),(0,l.kt)("p",null,"Head over to the ",(0,l.kt)("a",{parentName:"p",href:"https://app.otterize.com/clusters"},"Clusters page")," and create a cluster.\nFollow the connection guide that opens to connect your cluster, and make the following changes:"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Under ",(0,l.kt)("inlineCode",{parentName:"p"},"mTLS and Kafka support")," choose ",(0,l.kt)("inlineCode",{parentName:"p"},"Otterize Cloud"),".")),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Note that enforcement is disabled, we will enable it later. The configuration tab should look like this:\n",(0,l.kt)("img",{alt:"Cluster connection guide",src:n(9654).Z,width:"1468",height:"824"}))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Copy the Helm command and ",(0,l.kt)("b",null,"add")," the following flags:"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre"},'--set intentsOperator.operator.enableNetworkPolicyCreation=false \\\n--set networkMapper.kafkawatcher.enable=true \\\n--set networkMapper.kafkawatcher.kafkaServers={"kafka-0.kafka"}\n')))),(0,l.kt)("h4",{id:"configure-the-access-graph-in-otterize-cloud-to-only-show-kafka-authorization-status"},"Configure the access graph in Otterize Cloud to only show Kafka authorization status"),(0,l.kt)("p",null,"You want to make sure that under ",(0,l.kt)("strong",{parentName:"p"},"Istio Policies")," ",(0,l.kt)("em",{parentName:"p"},"Use in access graph")," is turned off and that under ",(0,l.kt)("strong",{parentName:"p"},"Network Policies")," ",(0,l.kt)("em",{parentName:"p"},"Use in access graph")," is also turned off."),(0,l.kt)("p",null,"Keep ",(0,l.kt)("em",{parentName:"p"},"Use in access graph")," ",(0,l.kt)("strong",{parentName:"p"},"on")," under ",(0,l.kt)("strong",{parentName:"p"},"Kafka ACLs")," so that the access graph only shows the authorization status for Kafka ACLs."),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Make sure access graph is configured correctly",src:n(7292).Z,width:"4270",height:"1080"})),(0,l.kt)("h2",{id:"install-kafka"},"Install Kafka"),(0,l.kt)("p",null,"We will deploy a Kafka broker using Bitnami's ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/bitnami/charts/tree/master/bitnami/kafka"},"Helm chart"),".\nIn the chart we will configure Kafka to:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Recognize the Otterize intents operator as a super user so it can configure ACLs;"),(0,l.kt)("li",{parentName:"ul"},"Use TLS/SSL for its listeners;"),(0,l.kt)("li",{parentName:"ul"},"Tell the Otterize credentials operator, via pod annotations, how credentials should be created;"),(0,l.kt)("li",{parentName:"ul"},"Authenticate clients using mTLS credentials provided as a Kubernetes secret; and"),(0,l.kt)("li",{parentName:"ul"},"Allow access to any topic by default unless denied by an ACL (achieved using ",(0,l.kt)("inlineCode",{parentName:"li"},"allowEveryoneIfNoAclFound: true"),").")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Expand to see the Helm values.yaml used with the Bitnami chart"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},'# Configure Otterize as a super user to grant it access to configure ACLs\nsuperUsers: "User:CN=kafka.kafka,O=SPIRE,C=US;User:CN=intents-operator.otterize-system,O=SPIRE,C=US;User:CN=kafka.kafka;User:CN=intents-operator.otterize-system"\n# Use TLS for the Kafka listeners (Kafka calls them SSL)\nlisteners:\n  - "CLIENT://:9092"\n  - "INTERNAL://:9093"\nadvertisedListeners:\n  - "CLIENT://:9092"\n  - "INTERNAL://:9093"\nlistenerSecurityProtocolMap: "INTERNAL:SSL,CLIENT:SSL"\n# For a gradual rollout scenario we will want to keep the default permission for topics as allowed, unless an ACL was set\nallowEveryoneIfNoAclFound: true\n# Annotations for Otterize to generate credentials\npodAnnotations:\n  credentials-operator.otterize.com/cert-type: jks\n  credentials-operator.otterize.com/tls-secret-name: kafka-tls-secret\n  credentials-operator.otterize.com/dns-names: "kafka-0.kafka-headless.kafka.svc.cluster.local,kafka.kafka.svc.cluster.local"\n# Authenticate clients using mTLS\nauth:\n  clientProtocol: mtls\n  interBrokerProtocol: mtls\n  tls:\n    type: jks\n    existingSecrets:\n      - kafka-tls-secret\n    password: password\n    jksTruststore: truststore.jks\n    jksKeystoreSAN: keystore.jks\nauthorizerClassName: kafka.security.authorizer.AclAuthorizer\n# Allocate resources\nresources:\n  requests:\n    cpu: 50m\n    memory: 256Mi\nlog4j: |\n  # Unspecified loggers and loggers with additivity=true output to server.log and stdout\n  # Note that INFO only applies to unspecified loggers, the log level of the child logger is used otherwise\n\n  log4j.rootLogger=INFO, stdout, kafkaAppender\n\n  log4j.appender.stdout=org.apache.log4j.ConsoleAppender\n  log4j.appender.stdout.layout=org.apache.log4j.PatternLayout\n  log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.kafkaAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.stateChangeAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.requestAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.requestAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.cleanerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.cleanerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.controllerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.controllerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.controllerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.authorizerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.authorizerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.authorizerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n\n  # Change the line below to adjust ZK client logging\n  log4j.logger.org.apache.zookeeper=INFO\n\n  # Change the two lines below to adjust the general broker logging level (output to server.log and stdout)\n  log4j.logger.kafka=INFO, stdout\n  log4j.logger.org.apache.kafka=INFO\n\n  # Change to DEBUG or TRACE to enable request logging\n  log4j.logger.kafka.request.logger=WARN, requestAppender\n  log4j.additivity.kafka.request.logger=false\n\n  # Uncomment the lines below and change log4j.logger.kafka.network.RequestChannel$ to TRACE for additional output\n  # related to the handling of requests\n  #log4j.logger.kafka.network.Processor=TRACE, requestAppender\n  #log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender\n  #log4j.additivity.kafka.server.KafkaApis=false\n  log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender\n  log4j.additivity.kafka.network.RequestChannel$=false\n\n  # Change the line below to adjust KRaft mode controller logging\n  log4j.logger.org.apache.kafka.controller=INFO, controllerAppender\n  log4j.additivity.org.apache.kafka.controller=false\n\n  # Change the line below to adjust ZK mode controller logging\n  log4j.logger.kafka.controller=TRACE, controllerAppender\n  log4j.additivity.kafka.controller=false\n\n  log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender\n  log4j.additivity.kafka.log.LogCleaner=false\n\n  log4j.logger.state.change.logger=INFO, stateChangeAppender\n  log4j.additivity.state.change.logger=false\n\n  # Access denials are logged at INFO level, change to DEBUG to also log allowed accesses\n  log4j.logger.kafka.authorizer.logger=DEBUG, authorizerAppender\n  log4j.additivity.kafka.authorizer.logger=false\n'))),(0,l.kt)("p",null,"The following command will deploy a Kafka broker with this chart:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"helm repo add bitnami https://charts.bitnami.com/bitnami\nhelm repo update\nhelm install --create-namespace -n kafka \\\n  -f ${ABSOLUTE_URL}/code-examples/kafka-mtls/helm/values.yaml kafka bitnami/kafka --version 21.4.4\n")),(0,l.kt)("p",null,"You can watch for all pods to be ",(0,l.kt)("inlineCode",{parentName:"p"},"Ready")," using ",(0,l.kt)("inlineCode",{parentName:"p"},"kubectl get pods -n kafka -w"),"."),(0,l.kt)("h2",{id:"configure-otterize-to-manage-kafka-access"},"Configure Otterize to manage Kafka access"),(0,l.kt)("p",null,"In our simple example, we'll call the Kafka broker service simply \"kafka\".\nLet's tell Otterize how to connect to the Kafka broker by applying an Otterize ",(0,l.kt)("inlineCode",{parentName:"p"},"KafkaServerConfig"),", naming it ",(0,l.kt)("inlineCode",{parentName:"p"},"kafka"),". The name will be the name we later use to declare ",(0,l.kt)("inlineCode",{parentName:"p"},"ClientIntents"),"."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f ${ABSOLUTE_URL}/code-examples/kafka-mtls/kafkaserverconfig.yaml\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: k8s.otterize.com/v1alpha3\nkind: KafkaServerConfig\nmetadata:\n  name: kafkaserverconfig\n  namespace: kafka\nspec:\n  service:\n    name: kafka\n  addr: kafka.kafka:9092\n")),(0,l.kt)("h2",{id:"deploy-clients"},"Deploy clients"),(0,l.kt)("p",null,"Our simple example consists of two client pods:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},'One named "',(0,l.kt)("strong",{parentName:"li"},"client"),'".'),(0,l.kt)("li",{parentName:"ul"},'And one named "',(0,l.kt)("strong",{parentName:"li"},"client-other"),'".')),(0,l.kt)("p",null,"These clients are connecting to Kafka using mTLS, the credentials which they will receive from Otterize. Otterize makes this easy, requiring just 4 simple changes:"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("strong",{parentName:"li"},"Generate credentials"),": add the ",(0,l.kt)("inlineCode",{parentName:"li"},"credentials-operator.otterize.com/tls-secret-name")," annotation, which tells Otterize to generate mTLS credentials and store them in a Kubernetes Secret whose name is the value of this annotation."),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("strong",{parentName:"li"},"Expose credentials in a volume"),": add a volume containing this secret to the pod."),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("strong",{parentName:"li"},"Mount the volume"),": mount the volume in the pod.")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Expand to see how to configure a Pod to mount the secret"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},'spec:\n  template:\n    metadata:\n      annotations:\n        # highlight-next-line\n        # 1. Generate credentials as a secret called "client-credentials-secret":\n        credentials-operator.otterize.com/tls-secret-name: client-credentials-secret\n        ...\n    spec:\n      volumes:\n        # highlight-start\n        # 2. Create a volume containing this secret:\n        - name: otterize-credentials\n          secret:\n            secretName: client-credentials-secret\n        # highlight-end\n        ...\n      containers:\n        - name: client\n          ...\n          volumeMounts:\n            # highlight-start\n            # 3. Mount volume into container\n            - name: otterize-credentials\n              mountPath: /var/otterize/credentials\n              readOnly: true\n            # highlight-end\n'))),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Expand to see the YAML for the pods used in this example"),(0,l.kt)(o.Z,{mdxType:"Tabs"},(0,l.kt)(r.Z,{value:"client-deployment.yaml",label:"client-deployment.yaml",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client\n  namespace: otterize-tutorial-kafka-mtls\nspec:\n  selector:\n    matchLabels:\n      app: client\n  template:\n    metadata:\n      labels:\n        app: client\n      annotations:\n        credentials-operator.otterize.com/tls-secret-name: client-credentials-secret\n    spec:\n      containers:\n        - name: client\n          image: otterize/tutorial-kafka-client:latest\n          imagePullPolicy: Always\n          volumeMounts:\n            - name: otterize-credentials\n              mountPath: /var/otterize/credentials\n              readOnly: true\n      volumes:\n        - name: otterize-credentials\n          secret:\n            secretName: client-credentials-secret\n        - name: ephemeral\n          emptyDir: { }\n"))),(0,l.kt)(r.Z,{value:"client-other-deployment.yaml",label:"client-other-deployment.yaml",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client-other\n  namespace: otterize-tutorial-kafka-mtls\nspec:\n  selector:\n    matchLabels:\n      app: client-other\n  template:\n    metadata:\n      labels:\n        app: client-other\n      annotations:\n        credentials-operator.otterize.com/tls-secret-name: client-other-credentials-secret\n    spec:\n      containers:\n        - name: client-other\n          image: otterize/tutorial-kafka-client-second:latest\n          imagePullPolicy: Always\n          volumeMounts:\n            - name: otterize-credentials\n              mountPath: /var/otterize/credentials\n              readOnly: true\n      volumes:\n        - name: otterize-credentials\n          secret:\n            secretName: client-other-credentials-secret\n        - name: ephemeral\n          emptyDir: { }\n"))))),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Deploy the two clients into a namespace called ",(0,l.kt)("inlineCode",{parentName:"li"},"otterize-tutorial-kafka-mtls")," using ",(0,l.kt)("inlineCode",{parentName:"li"},"kubectl"),":")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f ${ABSOLUTE_URL}/code-examples/kafka-mtls/all.yaml\n")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Optional: check deployment status"),(0,l.kt)("p",null,"Check that the client pods were deployed:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pods -n otterize-tutorial-kafka-mtls\n")),(0,l.kt)("p",null,"You should see:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"NAME                                    READY   STATUS    RESTARTS   AGE\nclient-65695dfc4c-jf4hd                 1/1     Running   0          92s\nclient-other-7c4b8cbd8d-dpkt6           1/1     Running   0          92s\n"))),(0,l.kt)("p",null,"Let's monitor, in separate terminal windows, both clients' attempts to call Kafka,\nso we can see the effects of our changes in real time."),(0,l.kt)("ol",{start:2},(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("strong",{parentName:"li"},"Open a new terminal window ","[client]")," and tail the client log:")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl logs -f --tail 1 -n otterize-tutorial-kafka-mtls deploy/client\n")),(0,l.kt)("p",null,"This client should be able to access both topics:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"[client] Loading mTLS certificates\n[client] Connecting to Kafka\n[client] Creating a producer and a consumer for - mytopic\n[client] Sending Messages\n[debug]  [client] Sent message 1 [mytopic]\n[client] Creating a producer and a consumer for - transactions\n[client] Sending messages\n[debug]  [client] Sent message 1 [transactions]\n[client] Sent message to topic: transactions - [client] Sent message 1 [transactions]\n[client] Sent message to topic: mytopic - [client] Sent message 1 [mytopic]\n[client] Read message from topic: mytopic - [client-other] Sent message 27 [mytopic]\n[client] Read message from topic: mytopic - [client-other] Sent message 18 [mytopic]\n[client] Read message from topic: mytopic - [client] Sent message 2 [mytopic]\n[client] Read message from topic: mytopic - [client-other] Sent message 36 [mytopic]\n[client] Read message from topic: mytopic - [client-other] Sent message 6 [mytopic]\n[client] Read message from topic: mytopic - [client-other] Sent message 33 [mytopic]\n[client] Read message from topic: mytopic - [client-other] Sent message 19 [mytopic]\n")),(0,l.kt)("p",null,"As you can see, both ",(0,l.kt)("inlineCode",{parentName:"p"},"client")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"client-other")," are currently able to access both ",(0,l.kt)("inlineCode",{parentName:"p"},"mytopic")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"transactions")," topics. (We see ",(0,l.kt)("inlineCode",{parentName:"p"},"client")," sending messages and reading messages sent by ",(0,l.kt)("inlineCode",{parentName:"p"},"client-other")," so we know both are able to access both topics.)"),(0,l.kt)("ol",{start:3},(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("strong",{parentName:"li"},"Open another terminal window ","[client-other]")," and tail the client-other log:")),(0,l.kt)("p",null,"This other client should also be able to access both topics:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl logs -f --tail 1 -n otterize-tutorial-kafka-mtls deploy/client-other\n[client-other] Loading mTLS certificates\n[client-other] Connecting to Kafka\n[client-other] Creating a producer and a consumer for - mytopic\n[client-other] Sending messages\n[client-other] Creating a producer and a consumer for - transactions\n[client-other] Sending messages\n[debug]  [client-other] Sent message 1 [mytopic]\n[debug]  [client-other] Sent message 1 [transactions]\n[client-other] Sent message to topic: transactions - [client-other] Sent message 1 [transactions]\n[client-other] Sent message to topic: mytopic - [client-other] Sent message 1 [mytopic]\n[client-other] Read message from topic: transactions - [client] Sent message 5 [transactions]\n")),(0,l.kt)("p",null,"You can now browse to your account at ",(0,l.kt)("a",{parentName:"p",href:"https://app.otterize.com"},"https://app.otterize.com")," and see the access graph for your cluster:"),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Access graph",src:n(7120).Z,width:"2302",height:"1111"})),(0,l.kt)("p",null,"The access graph shows, through its green and orange lines linking the services, that no clients are currently blocked because we haven't enabled any sort of enforcement yet. The orange lines indicate that, since we have not declared any intents for these clients, they ",(0,l.kt)("em",{parentName:"p"},"would")," be blocked if we were to turn enforcement on."),(0,l.kt)("h2",{id:"apply-intents"},"Apply intents"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"The client declares its intent to call the ",(0,l.kt)("inlineCode",{parentName:"li"},"kafka.kafka")," server with this ",(0,l.kt)("inlineCode",{parentName:"li"},"intents.yaml")," file:")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: k8s.otterize.com/v1alpha3\nkind: ClientIntents\nmetadata:\n  name: client\n  namespace:  otterize-tutorial-kafka-mtls\nspec:\n  service:\n    name: client\n  calls:\n    - name: kafka.kafka\n      type: kafka\n      kafkaTopics:\n        - name: mytopic\n          operations: [ produce,describe,consume ]\n        - name: transactions\n          operations: [ produce,describe,consume ]\n\n")),(0,l.kt)("p",null,"We can apply intents for the ",(0,l.kt)("inlineCode",{parentName:"p"},"client")," by applying the ",(0,l.kt)("inlineCode",{parentName:"p"},"client-intents.yaml")," file:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f ${ABSOLUTE_URL}/code-examples/kafka-mtls/client-intents.yaml\n")),(0,l.kt)("p",null,"If you go back to your access graph, you'll now see that the ",(0,l.kt)("inlineCode",{parentName:"p"},"client")," has a solid green line connecting it to the Kafka broker. This is because the ",(0,l.kt)("inlineCode",{parentName:"p"},"client")," has both declared its intent to access the Kafka broker, and it has been authenticated using mTLS."),(0,l.kt)("p",null,"If you click on that solid line, you will see that the declared intents match the discovered intents, so access is assured."),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"client intents applied",src:n(6582).Z,width:"707",height:"340"})),(0,l.kt)("ol",{start:2},(0,l.kt)("li",{parentName:"ol"},"At this point, since the Kafka server is not actually protected, the ",(0,l.kt)("inlineCode",{parentName:"li"},"client-other")," can still access the topics. The line is orange, indicating that it has no declared intents.")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Declared Intent",src:n(7632).Z,width:"2286",height:"1112"})),(0,l.kt)("p",null,"We can see what happened:"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Kafka topic-specific intents from ",(0,l.kt)("strong",{parentName:"li"},"[client]")," are declared (solid green line)."),(0,l.kt)("li",{parentName:"ol"},"Calls from ",(0,l.kt)("strong",{parentName:"li"},"[client-other]")," are not declared (orange line)."),(0,l.kt)("li",{parentName:"ol"},"Looking at the Kafka service, we can see that ",(0,l.kt)("strong",{parentName:"li"},"[client]")," has specific access configured (via Kafka ACLs) to perform ",(0,l.kt)("inlineCode",{parentName:"li"},"all")," operations on the ",(0,l.kt)("inlineCode",{parentName:"li"},"mytopic")," topic.")),(0,l.kt)("p",null,"Also, the access graph shows information about the mTLS certificates (credentials) distributed to the various services, as long as ",(0,l.kt)("a",{parentName:"p",href:"/security#cryptographic-credentials"},"Cloud-managed credentials")," are being used."),(0,l.kt)("h2",{id:"turn-on-protection"},"Turn on protection"),(0,l.kt)("p",null,"At this point, we haven't actually protected our Kafka broker. From everything we've done so far, we can see, however, that if we were to turn on protection, the ",(0,l.kt)("inlineCode",{parentName:"p"},"client-other")," would lose access to the broker."),(0,l.kt)("p",null,"Let's see that in action. Our clients that have not declared intents will be blocked from accessing the broker."),(0,l.kt)("p",null,"We need to turn protection on in for this Kafka broker by declaring it as a protected service:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: k8s.otterize.com/v1alpha2\nkind: ProtectedService\nmetadata:\n  name: kafka-protectedservice\n  namespace: kafka\nspec:\n  name: kafka\n")),(0,l.kt)("p",null,"Apply this ",(0,l.kt)("inlineCode",{parentName:"p"},"ProtectedService")," resource:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl apply -f ${ABSOLUTE_URL}/code-examples/kafka-mtls-cert-manager/protectedservice.yaml\n")),(0,l.kt)("p",null,"If you once again tail the logs for ",(0,l.kt)("inlineCode",{parentName:"p"},"client-other")," you'll see that it is no longer authorized to access this topic:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},'[client-other] Loading mTLS certificates\n[client-other] Connecting to Kafka\n[client-other] Creating a producer and a consumer for - transactions\n[client] Sending messages\n[client-other] Creating a producer and a consumer for - transactions\n[client] Sending messages\ntime="[...]" level=error msg="Failed reading/writing to Kafka"\nerror="kafka server: The client is not authorized to access this topic\n')),(0,l.kt)("p",null,"And if you look back at your access graph, you'll see that the Kafka broker is now protected, and that the ",(0,l.kt)("inlineCode",{parentName:"p"},"client-other")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"client-authenticated")," are blocked."),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Clients blocked",src:n(1541).Z,width:"1916",height:"926"})),(0,l.kt)("h2",{id:"what-did-we-accomplish"},"What did we accomplish?"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Controlling Kafka access no longer means touching ACLs, issuing and managing and distributing certs, establishing trust,\netc.")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"As we saw with pod-to-pod access, clients simply declare with their intents files the Kafka access they need,\nand define a place on their filesystem where they'll get the appropriate credentials (certs).")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"The next ",(0,l.kt)("inlineCode",{parentName:"p"},"kubectl apply")," ensures that all the appropriate certs are issued and distributed,\nand that Kafka ACLs are configured to reflect precisely the intended topic-level access."))),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Expand to see what happened behind the scenes"),(0,l.kt)("h3",{id:"one-time-setups"},"One-time setups"),(0,l.kt)("p",null,"We configured the Helm chart for Kafka to:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Allow the Otterize intents operator to be a Kafka super user (authenticated with a certificate)."),(0,l.kt)("li",{parentName:"ul"},"Use the SSL protocol for the Kafka listeners."),(0,l.kt)("li",{parentName:"ul"},"Let Otterize know it should generate mTLS credentials in the Java Key Store and Java Trust Store formats, and store them as a Kubernetes secret."),(0,l.kt)("li",{parentName:"ul"},"Use mTLS to authenticate clients, using this Kubernetes secret.")),(0,l.kt)("p",null,"We configured Kafka itself to:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Add the TLS certificates of the Otterize credentials operator."),(0,l.kt)("li",{parentName:"ul"},"Set the default ACL for all topics to allow anonymous access.")),(0,l.kt)("h3",{id:"per-client-setups"},"Per-client setups"),(0,l.kt)("p",null,"We configured each of our clients to:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Let Otterize know it should generate mTLS credentials for that client."),(0,l.kt)("li",{parentName:"ul"},"Mount the Kubernetes secret in a local volume.")),(0,l.kt)("p",null,"This already enables mTLS authentication between both clients and Kafka."),(0,l.kt)("p",null,"Then we applied intents:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"We only declared that the ",(0,l.kt)("em",{parentName:"li"},"client")," pod (not the ",(0,l.kt)("em",{parentName:"li"},"client-other")," pod) needed to access the ",(0,l.kt)("inlineCode",{parentName:"li"},"mytopic")," topic.")),(0,l.kt)("p",null,"This allowed the ",(0,l.kt)("em",{parentName:"p"},"client")," pod its access and protected ",(0,l.kt)("inlineCode",{parentName:"p"},"mytopic")," from any unintended access, such as from ",(0,l.kt)("em",{parentName:"p"},"client-other"),".")),(0,l.kt)("h2",{id:"teardown"},"Teardown"),(0,l.kt)("admonition",{type:"caution"},(0,l.kt)("p",{parentName:"admonition"},"Take care to remove the intents before removing the KafkaServerConfig or the Kafka broker, as the operator will not know how to remove\nthe intents if you first make it forget about the Kafka broker or it can't access the broker.\nIf it's unable to remove the ACLs for the intents, the operator will prevent the intents from being deleted until\nit is able to do so.")),(0,l.kt)("p",null,"To remove the deployed examples run:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"# run this first:\nkubectl delete -f ${ABSOLUTE_URL}/code-examples/kafka-mtls/client-intents.yaml\n# then the rest:\nkubectl delete -f ${ABSOLUTE_URL}/code-examples/kafka-mtls/all.yaml\nkubectl delete -f ${ABSOLUTE_URL}/code-examples/kafka-mtls/kafkaserverconfig.yaml\nhelm uninstall kafka -n kafka\n")))}k.isMDXComponent=!0},9654:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/connect-cluster-kafka-mtls-with-otterize-cloud-48f7526d8ec7b22f5c7e67d03016bee7.png"},7120:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/base-60e98d7f9e45b13e50a22cdbbaeabb29.png"},6582:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/client-intents-d7835ae003d908391a2b5e2db04afd47.png"},1541:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/clients-blocked-56a5c5fbac0d840d1c9489d0dbd11579.png"},7292:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/cloud-settings-58edcdf753437fc316e094019df05b6b.png"},7632:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/declared-intent-313450adb04eb54d4f8c828d24b3d437.png"}}]);