"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9041],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>k});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},u=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),c=p(a),g=r,k=c["".concat(s,".").concat(g)]||c[g]||d[g]||o;return a?n.createElement(k,l(l({ref:t},u),{},{components:a})):n.createElement(k,l({ref:t},u))}));function k(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,l=new Array(o);l[0]=g;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[c]="string"==typeof e?e:r,l[1]=i;for(var p=2;p<o;p++)l[p]=a[p];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},5162:(e,t,a)=>{a.d(t,{Z:()=>l});var n=a(7294),r=a(6010);const o={tabItem:"tabItem_Ymn6"};function l(e){let{children:t,hidden:a,className:l}=e;return n.createElement("div",{role:"tabpanel",className:(0,r.Z)(o.tabItem,l),hidden:a},t)}},4866:(e,t,a)=>{a.d(t,{Z:()=>w});var n=a(7462),r=a(7294),o=a(6010),l=a(2466),i=a(6550),s=a(1980),p=a(7392),u=a(12);function c(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:a,attributes:n,default:r}}=e;return{value:t,label:a,attributes:n,default:r}}))}function d(e){const{values:t,children:a}=e;return(0,r.useMemo)((()=>{const e=t??c(a);return function(e){const t=(0,p.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,a])}function g(e){let{value:t,tabValues:a}=e;return a.some((e=>e.value===t))}function k(e){let{queryString:t=!1,groupId:a}=e;const n=(0,i.k6)(),o=function(e){let{queryString:t=!1,groupId:a}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:t,groupId:a});return[(0,s._X)(o),(0,r.useCallback)((e=>{if(!o)return;const t=new URLSearchParams(n.location.search);t.set(o,e),n.replace({...n.location,search:t.toString()})}),[o,n])]}function f(e){const{defaultValue:t,queryString:a=!1,groupId:n}=e,o=d(e),[l,i]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!g({value:t,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const n=a.find((e=>e.default))??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:o}))),[s,p]=k({queryString:a,groupId:n}),[c,f]=function(e){let{groupId:t}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(t),[n,o]=(0,u.Nk)(a);return[n,(0,r.useCallback)((e=>{a&&o.set(e)}),[a,o])]}({groupId:n}),h=(()=>{const e=s??c;return g({value:e,tabValues:o})?e:null})();(0,r.useLayoutEffect)((()=>{h&&i(h)}),[h]);return{selectedValue:l,selectValue:(0,r.useCallback)((e=>{if(!g({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);i(e),p(e),f(e)}),[p,f,o]),tabValues:o}}var h=a(2389);const m={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function b(e){let{className:t,block:a,selectedValue:i,selectValue:s,tabValues:p}=e;const u=[],{blockElementScrollPositionUntilNextRender:c}=(0,l.o5)(),d=e=>{const t=e.currentTarget,a=u.indexOf(t),n=p[a].value;n!==i&&(c(t),s(n))},g=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const a=u.indexOf(e.currentTarget)+1;t=u[a]??u[0];break}case"ArrowLeft":{const a=u.indexOf(e.currentTarget)-1;t=u[a]??u[u.length-1];break}}t?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":a},t)},p.map((e=>{let{value:t,label:a,attributes:l}=e;return r.createElement("li",(0,n.Z)({role:"tab",tabIndex:i===t?0:-1,"aria-selected":i===t,key:t,ref:e=>u.push(e),onKeyDown:g,onClick:d},l,{className:(0,o.Z)("tabs__item",m.tabItem,l?.className,{"tabs__item--active":i===t})}),a??t)})))}function y(e){let{lazy:t,children:a,selectedValue:n}=e;const o=(Array.isArray(a)?a:[a]).filter(Boolean);if(t){const e=o.find((e=>e.props.value===n));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},o.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==n}))))}function v(e){const t=f(e);return r.createElement("div",{className:(0,o.Z)("tabs-container",m.tabList)},r.createElement(b,(0,n.Z)({},e,t)),r.createElement(y,(0,n.Z)({},e,t)))}function w(e){const t=(0,h.Z)();return r.createElement(v,(0,n.Z)({key:String(t)},e))}},296:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>p});var n=a(7462),r=(a(7294),a(3905));a(4866),a(5162),a(3875);const o={sidebar_position:3,title:"Kafka topic-level access mapping",image:"/img/visualization/k8s-kafka-mapping/social.png"},l=void 0,i={unversionedId:"features/kafka/tutorials/k8s-kafka-mapping",id:"features/kafka/tutorials/k8s-kafka-mapping",title:"Kafka topic-level access mapping",description:"With its Kafka watcher enabled, the network mapper allows you to map topic-level access to Kafka servers within your Kubernetes cluster.",source:"@site/docs/features/kafka/tutorials/k8s-kafka-mapping.mdx",sourceDirName:"features/kafka/tutorials",slug:"/features/kafka/tutorials/k8s-kafka-mapping",permalink:"/features/kafka/tutorials/k8s-kafka-mapping",draft:!1,editUrl:"https://github.com/otterize/docs/edit/main/docs/features/kafka/tutorials/k8s-kafka-mapping.mdx",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,title:"Kafka topic-level access mapping",image:"/img/visualization/k8s-kafka-mapping/social.png"},sidebar:"docSidebar",previous:{title:"Kafka | Overview",permalink:"/features/kafka/"},next:{title:"Kafka access automation using Otterize Cloud mTLS",permalink:"/features/kafka/tutorials/k8s-kafka-mtls"}},s={},p=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"1. Deploy Otterize",id:"1-deploy-otterize",level:3},{value:"2. Install Kafka",id:"2-install-kafka",level:3},{value:"Tutorial",id:"tutorial",level:2},{value:"Deploy demo to simulate traffic",id:"deploy-demo-to-simulate-traffic",level:3},{value:"What did we accomplish?",id:"what-did-we-accomplish",level:3},{value:"What&#39;s next",id:"whats-next",level:3},{value:"Teardown",id:"teardown",level:2}],u={toc:p},c="wrapper";function d(e){let{components:t,...o}=e;return(0,r.kt)(c,(0,n.Z)({},u,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"With its Kafka watcher enabled, the network mapper allows you to map topic-level access to Kafka servers within your Kubernetes cluster.\nThis provides a clear picture of which Kafka topics are being accessed and with which operations.\nIn this tutorial, we will:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Deploy a Kafka broker, and three clients that call it."),(0,r.kt)("li",{parentName:"ul"},"Discover which topics are being accessed by those clients, and with which operations, using the Otterize network mapper's Kafka watcher.")),(0,r.kt)("p",null,"We will ",(0,r.kt)("strong",{parentName:"p"},"not")," be doing any access control in this demo, just purely mapping client-to-Kafka access at the topic and operation level."),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("p",null,"Already have Otterize & a Kafka broker deployed on your cluster? Skip to the ",(0,r.kt)("a",{parentName:"p",href:"#tutorial"},"tutorial"),"."),(0,r.kt)("h3",{id:"1-deploy-otterize"},"1. Deploy Otterize"),(0,r.kt)("p",null,"To deploy Otterize, head over to ",(0,r.kt)("a",{parentName:"p",href:"https://app.otterize.com"},"Otterize Cloud")," and associate a Kubernetes cluster on the ",(0,r.kt)("a",{parentName:"p",href:"https://app.otterize.com/integrations"},"Integrations page"),", and follow the instructions. If you already have a Kubernetes cluster connected, skip this step."),(0,r.kt)("h3",{id:"2-install-kafka"},"2. Install Kafka"),(0,r.kt)("p",null,"We will deploy a Kafka broker using Bitnami's ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/bitnami/charts/tree/master/bitnami/kafka"},"Helm chart"),".\nIn the chart we will configure Kafka to:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Recognize the Otterize intents operator as a super user so it can configure ACLs."),(0,r.kt)("li",{parentName:"ul"},"Turn on Kafka debug logging to allow the Kafka watcher to feed topic-level client access information to the network mapper.")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Expand to see the Helm values.yaml used with the Bitnami chart"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'listeners:\n  - "CLIENT://:9092"\n  - "INTERNAL://:9093"\nadvertisedListeners:\n  - "CLIENT://:9092"\n  - "INTERNAL://:9093"\n# For a gradual rollout scenario we will want to keep the default permission for topics as allowed, unless an ACL was set\nallowEveryoneIfNoAclFound: true\n# Allocate resources\nresources:\n  requests:\n    cpu: 50m\n    memory: 256Mi\nlog4j: |\n  # Unspecified loggers and loggers with additivity=true output to server.log and stdout\n  # Note that INFO only applies to unspecified loggers, the log level of the child logger is used otherwise\n  \n  log4j.rootLogger=INFO, stdout, kafkaAppender\n\n  log4j.appender.stdout=org.apache.log4j.ConsoleAppender\n  log4j.appender.stdout.layout=org.apache.log4j.PatternLayout\n  log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.kafkaAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.stateChangeAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.requestAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.requestAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.cleanerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.cleanerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.controllerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.controllerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.controllerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.authorizerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.authorizerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.authorizerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n\n  # Change the line below to adjust ZK client logging\n  log4j.logger.org.apache.zookeeper=INFO\n\n  # Change the two lines below to adjust the general broker logging level (output to server.log and stdout)\n  log4j.logger.kafka=INFO, stdout\n  log4j.logger.org.apache.kafka=INFO\n\n  # Change to DEBUG or TRACE to enable request logging\n  log4j.logger.kafka.request.logger=WARN, requestAppender\n  log4j.additivity.kafka.request.logger=false\n\n  # Uncomment the lines below and change log4j.logger.kafka.network.RequestChannel$ to TRACE for additional output\n  # related to the handling of requests\n  #log4j.logger.kafka.network.Processor=TRACE, requestAppender\n  #log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender\n  #log4j.additivity.kafka.server.KafkaApis=false\n  log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender\n  log4j.additivity.kafka.network.RequestChannel$=false\n\n  # Change the line below to adjust KRaft mode controller logging\n  log4j.logger.org.apache.kafka.controller=INFO, controllerAppender\n  log4j.additivity.org.apache.kafka.controller=false\n\n  # Change the line below to adjust ZK mode controller logging\n  log4j.logger.kafka.controller=TRACE, controllerAppender\n  log4j.additivity.kafka.controller=false\n\n  log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender\n  log4j.additivity.kafka.log.LogCleaner=false\n\n  log4j.logger.state.change.logger=INFO, stateChangeAppender\n  log4j.additivity.state.change.logger=false\n\n  # Access denials are logged at INFO level, change to DEBUG to also log allowed accesses\n  log4j.logger.kafka.authorizer.logger=DEBUG, authorizerAppender\n  log4j.additivity.kafka.authorizer.logger=false\nauthorizerClassName: kafka.security.authorizer.AclAuthorizer\n\n'))),(0,r.kt)("p",null,"The following command will deploy a Kafka broker with this chart:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"helm repo add bitnami https://charts.bitnami.com/bitnami\nhelm repo update\nhelm install --create-namespace -n kafka \\\n  -f ${ABSOLUTE_URL}/code-examples/kafka-mapping/helm/values.yaml kafka bitnami/kafka --version 21.4.4\n")),(0,r.kt)("h2",{id:"tutorial"},"Tutorial"),(0,r.kt)("h3",{id:"deploy-demo-to-simulate-traffic"},"Deploy demo to simulate traffic"),(0,r.kt)("p",null,"Let's add a few services that will access our Kafka server, and see how the network mapper builds the access map:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},'One service named "',(0,r.kt)("strong",{parentName:"li"},"client"),'".'),(0,r.kt)("li",{parentName:"ul"},'One service named "',(0,r.kt)("strong",{parentName:"li"},"client-2"),'".')),(0,r.kt)("p",null,"To deploy these services, use:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl apply -n otterize-tutorial-kafka-mapping -f ${ABSOLUTE_URL}/code-examples/kafka-mapping/all.yaml\n")),(0,r.kt)("p",null,"Each of these services is built to periodically call the Kafka broker we deployed. Because that broker has the Otterize OSS Kafka watcher enabled and feeding data to the network mapper, we can query the network mapper directly to see the map it has built up."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"otterize network-mapper list -n otterize-tutorial-kafka-mapping\n")),(0,r.kt)("p",null,"We expect to see:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"client")," consuming from ",(0,r.kt)("inlineCode",{parentName:"li"},"mytopic"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"client-2")," producing to ",(0,r.kt)("inlineCode",{parentName:"li"},"mytopic"),".")),(0,r.kt)("p",null,"And indeed:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"client in namespace otterize-tutorial-kafka-mapping calls:\n  - kafka in namespace kafka\n    - Kafka topic: transactions, operations: [describe]\n    - Kafka topic: mytopic, operations: [describe consume]\nclient-2 in namespace otterize-tutorial-kafka-mapping calls:\n  - kafka in namespace kafka\n    - Kafka topic: transactions, operations: [describe]\n    - Kafka topic: mytopic, operations: [produce describe]\n")),(0,r.kt)("p",null,"If you've attached Otterize OSS to Otterize Cloud, go back to see the ",(0,r.kt)("a",{parentName:"p",href:"https://app.otterize.com"},"access graph in your browser"),".\n",(0,r.kt)("strong",{parentName:"p"},"To only see Kafka information"),", make sure to de-select the 'Use in access graph' settings for network policies and Istio policies, and leave Kafka ACLs selected, like so:\n",(0,r.kt)("img",{alt:"Access graph settings",src:a(6188).Z,width:"788",height:"135"})),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Access graph",src:a(2135).Z,width:"1374",height:"687"}),"\nOnly the arrows between the clients and the Kafka are green, because we've selected Kafka ACLs for access graph. The other arrows were detected through network mapping, but since there's no Kafka mapping for those arrows, they are grayed out."),(0,r.kt)("p",null,"Clicking on a specific arrow between a client and the broker reveals which topic and operations are being accessed."),(0,r.kt)("h3",{id:"what-did-we-accomplish"},"What did we accomplish?"),(0,r.kt)("p",null,"Enabling the Kafka watcher component of the network mapper shows which clients connect to running Kafka servers, the topics they access, and the operations they undertake on those topics."),(0,r.kt)("p",null,"You can consume this information in various ways:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Visually via the access graph, where shadow mode shows you what would in enforcement mode before actually turning on enforcement, and auto-generating client intents to bootstrap rolling out IBAC."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/reference/cli"},"Via the CLI"),": from the network mapper directly or the cloud."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://app.otterize.com/api/rest/v1beta"},"Via the API"),".")),(0,r.kt)("h3",{id:"whats-next"},"What's next"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Try our ",(0,r.kt)("a",{parentName:"li",href:"/quickstart/access-control/k8s-kafka-mtls"},"secure access for Kafka")," tutorial")),(0,r.kt)("h2",{id:"teardown"},"Teardown"),(0,r.kt)("p",null,"To remove the deployed examples run:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"helm uninstall otterize -n otterize-system\nhelm uninstall kafka -n kafka\nhelm delete ns otterize-tutorial-kafka-mapping\n")))}d.isMDXComponent=!0},3875:()=>{},2135:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/discovered-84c1a90372557aff43ceb82ec61f9766.png"},6188:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/settings-2bfc6ec0150b3edf11559bfd113eaf61.png"}}]);