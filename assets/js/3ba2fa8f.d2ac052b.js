"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9184],{5680:(e,a,n)=>{n.d(a,{xA:()=>s,yg:()=>f});var t=n(6540);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function o(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function l(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?o(Object(n),!0).forEach((function(a){r(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function i(e,a){if(null==e)return{};var n,t,r=function(e,a){if(null==e)return{};var n,t,r={},o=Object.keys(e);for(t=0;t<o.length;t++)n=o[t],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)n=o[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var g=t.createContext({}),p=function(e){var a=t.useContext(g),n=a;return e&&(n="function"==typeof e?e(a):l(l({},a),e)),n},s=function(e){var a=p(e.components);return t.createElement(g.Provider,{value:a},e.children)},d="mdxType",c={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},u=t.forwardRef((function(e,a){var n=e.components,r=e.mdxType,o=e.originalType,g=e.parentName,s=i(e,["components","mdxType","originalType","parentName"]),d=p(n),u=r,f=d["".concat(g,".").concat(u)]||d[u]||c[u]||o;return n?t.createElement(f,l(l({ref:a},s),{},{components:n})):t.createElement(f,l({ref:a},s))}));function f(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var o=n.length,l=new Array(o);l[0]=u;var i={};for(var g in a)hasOwnProperty.call(a,g)&&(i[g]=a[g]);i.originalType=e,i[d]="string"==typeof e?e:r,l[1]=i;for(var p=2;p<o;p++)l[p]=n[p];return t.createElement.apply(null,l)}return t.createElement.apply(null,n)}u.displayName="MDXCreateElement"},3068:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>g,contentTitle:()=>l,default:()=>c,frontMatter:()=>o,metadata:()=>i,toc:()=>p});var t=n(8168),r=(n(6540),n(5680));const o={sidebar_position:2,title:"Kafka Watcher"},l=void 0,i={unversionedId:"reference/configuration/network-mapper/kafka-watcher",id:"reference/configuration/network-mapper/kafka-watcher",title:"Kafka Watcher",description:"To deploy the network mapper with the Kafka watcher component, do the following:",source:"@site/docs/reference/configuration/network-mapper/kafka-watcher.mdx",sourceDirName:"reference/configuration/network-mapper",slug:"/reference/configuration/network-mapper/kafka-watcher",permalink:"/reference/configuration/network-mapper/kafka-watcher",draft:!1,editUrl:"https://github.com/otterize/docs/edit/main/docs/reference/configuration/network-mapper/kafka-watcher.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,title:"Kafka Watcher"},sidebar:"docSidebar",previous:{title:"Helm chart",permalink:"/reference/configuration/network-mapper/helm-chart"},next:{title:"CLI",permalink:"/reference/cli/"}},g={},p=[{value:"Kafka watcher parameters",id:"kafka-watcher-parameters",level:2},{value:"Enabling debug logs in Kafka servers",id:"enabling-debug-logs-in-kafka-servers",level:2},{value:"Install Kafka via Helm with debug logs preconfigured",id:"install-kafka-via-helm-with-debug-logs-preconfigured",level:3},{value:"Configure an already running Kafka server",id:"configure-an-already-running-kafka-server",level:3}],s={toc:p},d="wrapper";function c(e){let{components:a,...n}=e;return(0,r.yg)(d,(0,t.A)({},s,n,{components:a,mdxType:"MDXLayout"}),(0,r.yg)("p",null,"To deploy the network mapper with the Kafka watcher component, do the following:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-bash"},"helm repo add otterize https://helm.otterize.com\nhelm repo update\nhelm install network-mapper otterize/network-mapper -n otterize-system --create-namespace --set kafkawatcher.enable=true\n")),(0,r.yg)("p",null,"Make sure to include ",(0,r.yg)("inlineCode",{parentName:"p"},"--set kafkaServers={}")," and provide a list of Kafka servers whose logs the Kafka watcher should watch.\nServers in the list should be specified as ",(0,r.yg)("inlineCode",{parentName:"p"},"name.namespace"),"."),(0,r.yg)("h2",{id:"kafka-watcher-parameters"},"Kafka watcher parameters"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Key"),(0,r.yg)("th",{parentName:"tr",align:null},"Description"),(0,r.yg)("th",{parentName:"tr",align:null},"Default"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"kafkawatcher.enable")),(0,r.yg)("td",{parentName:"tr",align:null},"Enable Kafka watcher deployment (beta)."),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"false"))),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"kafkawatcher.repository")),(0,r.yg)("td",{parentName:"tr",align:null},"Kafka watcher image repository."),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"otterize"))),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"kafkawatcher.image")),(0,r.yg)("td",{parentName:"tr",align:null},"Kafka watcher image."),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"network-mapper-kafka-watcher"))),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"kafkawatcher.tag")),(0,r.yg)("td",{parentName:"tr",align:null},"Kafka watcher image tag."),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"(pinned to latest version as of this Helm chart version's publish)"))),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"kafkawatcher.pullPolicy")),(0,r.yg)("td",{parentName:"tr",align:null},"Kafka watcher pull policy."),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"(none)"))),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"kafkawatcher.pullSecrets")),(0,r.yg)("td",{parentName:"tr",align:null},"Kafka watcher pull secrets."),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"(none)"))),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"kafkawatcher.resources")),(0,r.yg)("td",{parentName:"tr",align:null},"Resources override."),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"(none)"))),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"kafkawatcher.kafkaServers")),(0,r.yg)("td",{parentName:"tr",align:null},"Kafka servers to watch, specified as ",(0,r.yg)("inlineCode",{parentName:"td"},"pod.namespace")," items."),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"(none)"))))),(0,r.yg)("h2",{id:"enabling-debug-logs-in-kafka-servers"},"Enabling debug logs in Kafka servers"),(0,r.yg)("p",null,"The Kafka watcher periodically examines logs of Kafka servers provided by the user through configuration,\nparses them and deduces topic-level access to Kafka from pods in the Kubernetes cluster.\nIn order for the Kafka watcher to correctly examine topic-level access, the Kafka server's ACL authorizer logger should be configured\nto log at debug level, and to stdout."),(0,r.yg)("h3",{id:"install-kafka-via-helm-with-debug-logs-preconfigured"},"Install Kafka via Helm with debug logs preconfigured"),(0,r.yg)("p",null,"For the Bitnami Kafka Helm chart used in other Kafka tutorials, we can add the following configuration to the chart's\n",(0,r.yg)("inlineCode",{parentName:"p"},"values.yaml")," to start Kafka with its ACL authorizer logging to stdout at debug level:"),(0,r.yg)("details",null,(0,r.yg)("summary",null,"Kafka debug logs values.yaml"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'log4j: |\n  # Licensed to the Apache Software Foundation (ASF) under one or more\n  # contributor license agreements.  See the NOTICE file distributed with\n  # this work for additional information regarding copyright ownership.\n  # The ASF licenses this file to You under the Apache License, Version 2.0\n  # (the "License"); you may not use this file except in compliance with\n  # the License.  You may obtain a copy of the License at\n  #\n  #    http://www.apache.org/licenses/LICENSE-2.0\n  #\n  # Unless required by applicable law or agreed to in writing, software\n  # distributed under the License is distributed on an "AS IS" BASIS,\n  # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  # See the License for the specific language governing permissions and\n  # limitations under the License.\n\n  # Unspecified loggers and loggers with additivity=true output to server.log and stdout\n  # Note that INFO only applies to unspecified loggers, the log level of the child logger is used otherwise\n  log4j.rootLogger=INFO, stdout, kafkaAppender\n\n  log4j.appender.stdout=org.apache.log4j.ConsoleAppender\n  log4j.appender.stdout.layout=org.apache.log4j.PatternLayout\n  log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.kafkaAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.stateChangeAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.requestAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.requestAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.cleanerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.cleanerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.controllerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.controllerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.controllerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n  log4j.appender.authorizerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.authorizerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.authorizerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n\n  # Change the line below to adjust ZK client logging\n  log4j.logger.org.apache.zookeeper=INFO\n\n  # Change the two lines below to adjust the general broker logging level (output to server.log and stdout)\n  log4j.logger.kafka=INFO, stdout\n  log4j.logger.org.apache.kafka=INFO\n\n  # Change to DEBUG or TRACE to enable request logging\n  log4j.logger.kafka.request.logger=WARN, requestAppender\n  log4j.additivity.kafka.request.logger=false\n\n  # Uncomment the lines below and change log4j.logger.kafka.network.RequestChannel$ to TRACE for additional output\n  # related to the handling of requests\n  #log4j.logger.kafka.network.Processor=TRACE, requestAppender\n  #log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender\n  #log4j.additivity.kafka.server.KafkaApis=false\n  log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender\n  log4j.additivity.kafka.network.RequestChannel$=false\n\n  # Change the line below to adjust KRaft mode controller logging\n  log4j.logger.org.apache.kafka.controller=INFO, controllerAppender\n  log4j.additivity.org.apache.kafka.controller=false\n\n  # Change the line below to adjust ZK mode controller logging\n  log4j.logger.kafka.controller=TRACE, controllerAppender\n  log4j.additivity.kafka.controller=false\n\n  log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender\n  log4j.additivity.kafka.log.LogCleaner=false\n\n  log4j.logger.state.change.logger=INFO, stateChangeAppender\n  log4j.additivity.state.change.logger=false\n\n  # Access denials are logged at INFO level, change to DEBUG to also log allowed accesses\n  log4j.logger.kafka.authorizer.logger=DEBUG, authorizerAppender\n  log4j.additivity.kafka.authorizer.logger=false\n')),(0,r.yg)("p",null,"Notice the ",(0,r.yg)("inlineCode",{parentName:"p"},"log4j.logger.kafka.authorizer.logger=DEBUG")," line that sets the ACL authorizer logger to debug level.")),(0,r.yg)("h3",{id:"configure-an-already-running-kafka-server"},"Configure an already running Kafka server"),(0,r.yg)("p",null,"Alternatively, we can also configure an already-running Kafka server and set its ACL authorizer logger level to debug.\nThe Kafka server must be configured to log to stdout so the Kafka watcher could examine its logs."),(0,r.yg)("p",null,"First, deploy an interactive Kafka client:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"kubectl apply -f ${ABSOLUTE_URL}/code-examples/ibac-for-kafka/client-deployment-no-creds.yaml\n")),(0,r.yg)("p",null,"Connect to the interactive Kafka client using shell (replace the pod name with the name from your cluster):"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"kubectl exec -it -n ibac-for-kafka interactive-869fc7b89b-rgmfm -- /bin/bash\n")),(0,r.yg)("p",null,"Once connected, use the interactive shell to configure the ACL authorizer's logging level:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},'$ cd opt/bitnami/kafka/\n# query existing logging settings. Replace "kafka.kafka:9092" with the relevant service name, namespace and port.\n$ bin/kafka-configs.sh --bootstrap-server kafka.kafka:9092 --describe --all --entity-type broker-loggers --entity-name 0  | grep authorizer\n  kafka.security.authorizer.AclAuthorizer=INFO sensitive=false synonyms={}\n  kafka.authorizer.logger=INFO sensitive=false synonyms={}\n# enable authorizer debug logging\n$ bin/kafka-configs.sh --bootstrap-server kafka.kafka:9092 --alter --add-config "kafka.authorizer.logger=DEBUG" --entity-type broker-loggers --entity-name 0\nCompleted updating config for broker-logger 0.\n')),(0,r.yg)("p",null,"Check out your Kafka server logs. You should now see log records indicating allow/denied connections\nfrom the ACL authorizer (assuming you have clients producing/consuming data from topics):"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"[2023-03-22 16:06:22,746] DEBUG operation = READ on resource = ResourcePattern(resourceType=TOPIC, name=mytopic, patternType=LITERAL) from host = 10.244.0.12 is ALLOW based on acl = User:* has ALLOW permission for operations: ALL from hosts: * (kafka.authorizer.logger)\n")))}c.isMDXComponent=!0}}]);